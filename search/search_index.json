{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AlgoFlow Documentation","text":"<p>AlgoFlow is a web-based quantitative trading platform.</p>"},{"location":"#links","title":"Links","text":"<ul> <li>Data Pipeline</li> <li>API Reference</li> <li>GitHub</li> </ul>"},{"location":"CONTRIBUTING/","title":"How to contribute","text":""},{"location":"CONTRIBUTING/#initial-steps","title":"Initial Steps","text":"<ul> <li>Install python 3.9 or higher (python 3.12 reccomended) from python website or system package manager</li> <li> <p>Check python version: `python3 --version'</p> </li> <li> <p>Call 225-975-5921 if you are unsure or have questions. </p> </li> </ul>"},{"location":"CONTRIBUTING/#1-clone-repo","title":"1. Clone repo","text":"<pre><code>git clone https://github.com/algoflow-quant/algoflow.git\ncd algoflow\n</code></pre>"},{"location":"CONTRIBUTING/#2-install-dependencies","title":"2. Install dependencies","text":""},{"location":"CONTRIBUTING/#frontend-setup","title":"Frontend Setup:","text":"<p>N/A Contact Caden Lund for more</p>"},{"location":"CONTRIBUTING/#backend-setup","title":"Backend Setup:","text":"<p><pre><code>cd backend\npython3 -m venv venv\nsource venv/bin/activate # On windows this is: venv\\Scripts\\activate   \npip install -r requirements.txt\n</code></pre> * Windows users should use WSL for development</p>"},{"location":"CONTRIBUTING/#3-setup-commit-tools","title":"3. Setup commit tools","text":""},{"location":"CONTRIBUTING/#install-commitizen-for-easy-guided-commits","title":"Install commitizen for easy guided commits:","text":"<pre><code># Exit virtual environment\ndeactivate\n# Install pipx for global python packages\nsudo apt install pipx # brew install pipx\n# Install commitizen for guided commits\npipx install commitizen\npipx ensurepath\n\n# Now use the following in place of git commit\ncz commit # Provides interactive helper for formatting\n</code></pre>"},{"location":"CONTRIBUTING/#install-pre-commit-hooks-optional-but-reccommended-catch-commit-errors-before-pushing-to-online-repo","title":"Install pre-commit hooks (Optional but reccommended, catch commit errors before pushing to online repo):","text":"<p>IMPORTANT * You will have to redo commit messages if they are in the wrong format!!! * Note that github actions will prevent you from committing improper messages to the repo. </p> <pre><code># Install pre-commit\npipx install pre-commit\n# Install the git hook\npre-commit install --hook-type commit-msg\n# Now bad commits get blocked locally (faster feedback)\n</code></pre>"},{"location":"CONTRIBUTING/#commit-message-formatting-rules","title":"Commit message formatting rules","text":"<p>All commits must follow the Conventional Commits format:</p> <p><code>type(scope): description</code></p> <p>Can also have a body and footer</p>"},{"location":"CONTRIBUTING/#types-required","title":"Types (Required)","text":"<ul> <li>feat: New feature for the user</li> <li>fix: Bug fix for the user</li> <li>docs: Documentation only changes</li> <li>style: Code style changes (formatting, semicolons, etc)</li> <li>refactor: Code change that neither fixes a bug nor adds a feature</li> <li>perf: Performance improvements</li> <li>test: Adding or updating tests</li> <li>build: Changes to build system or dependencies</li> <li>ci: Changes to CI configuration files and scripts</li> <li>chore: Other changes that don't modify src or test files</li> <li>revert: Reverts a previous commit</li> </ul>"},{"location":"CONTRIBUTING/#scope-optional","title":"Scope (Optional)","text":"<p>The scope should indicate what part of the codebase changed: - <code>backend</code>, <code>frontend</code>, <code>api</code>, <code>db</code>, <code>auth</code>, <code>ui</code>, etc.</p>"},{"location":"CONTRIBUTING/#description-rules","title":"Description Rules","text":"<ul> <li>Use imperative mood (\"add\" not \"added\" or \"adds\")</li> <li>Don't capitalize first letter</li> <li>No period at the end</li> <li>Keep under 72 characters</li> </ul>"},{"location":"CONTRIBUTING/#examples","title":"Examples","text":"<p>Good commits: <pre><code>feat(auth): add OAuth2 login with Google\nfix(api): resolve timeout on stock api\ndocs: update stock database installation instructions in README\n</code></pre></p>"},{"location":"CONTRIBUTING/#other-stuff","title":"Other stuff","text":"<p>For breaking changes, add ! after type/scope and explain in body:</p> <p><code>feat(api)!: change user endpoint response format</code></p> <p>For complex changes, add a body: <pre><code>git commit -m \"feat(backtest): integrate backtesting queue\" -m \"\n- Addded priority queue for backtest nodes\n- Created installation scripts to deploy multiple backtest nodes\n- Added a load balancer to route backtests\n- Update database schema\"\n</code></pre></p>"},{"location":"CONTRIBUTING/#branch-workflow","title":"Branch workflow","text":""},{"location":"CONTRIBUTING/#protected-branches","title":"Protected Branches","text":"<ul> <li>main: Production-ready code (protected, requires PR + review)</li> <li>dev: Integration branch for features (protected, requires PR + review)</li> <li>Never push directly to main or dev!</li> </ul>"},{"location":"CONTRIBUTING/#branch-naming-convention","title":"Branch Naming Convention","text":"<p>Use descriptive branch names with these prefixes:</p> <ul> <li><code>feature/</code> - New features or enhancements</li> <li><code>bugfix/</code> - Bug fixes (non-urgent)</li> <li><code>hotfix/</code> - Urgent production fixes</li> <li><code>docs/</code> - Documentation only changes</li> <li><code>refactor/</code> - Code refactoring (no functionality change)</li> <li><code>test/</code> - Adding or updating tests</li> <li><code>chore/</code> - Maintenance tasks</li> </ul> <p>Examples: - feature/user-authentication - feature/portfolio-analytics - bugfix/chart-rendering-error</p>"},{"location":"CONTRIBUTING/#creating-a-branch","title":"Creating a Branch","text":"<p>Always start from dev: <pre><code>git checkout dev\ngit pull origin dev\ngit checkout -b feature/your-feature-name\n</code></pre></p>"},{"location":"CONTRIBUTING/#working-on-your-branch","title":"Working on your branch","text":"<p>After Changes <pre><code>git add .\ngit commit -m \"feat: add new feature\" \n\n# Keep branch updated with dev\ngit fetch origin\ngit rebase origin/dev  # or merge if you prefer\n\ngit push origin feature/your-feature-name\n</code></pre></p>"},{"location":"CONTRIBUTING/#pull-request-process","title":"Pull Request Process","text":""},{"location":"CONTRIBUTING/#1-push-branch-to-github","title":"1. Push branch to GitHub","text":"<pre><code>git push origin feature/your-feature # Make sure you branch off of dev\n</code></pre>"},{"location":"CONTRIBUTING/#2-create-pull-request","title":"2. Create Pull request","text":"<p>On GitHub: - Click \"Compare &amp; pull request\" button - Base: dev (NEVER directly to main) - Compare: your feature branch</p> <p>PR Title: - Use clear, descriptive title - Example: \"Add portfolio analytics dashboard\"</p> <p>PR Description Template:</p>"},{"location":"CONTRIBUTING/#what","title":"What","text":"<p>Brief description of changes</p>"},{"location":"CONTRIBUTING/#why","title":"Why","text":"<p>Problem this solves or feature it adds</p>"},{"location":"CONTRIBUTING/#how","title":"How","text":"<p>Technical approach taken</p>"},{"location":"CONTRIBUTING/#testing","title":"Testing","text":"<p>How you tested the changes</p>"},{"location":"CONTRIBUTING/#screenshots-if-ui-changes","title":"Screenshots (if UI changes)","text":"<p>[Add screenshots here]</p>"},{"location":"CONTRIBUTING/#checklist","title":"Checklist","text":"<ul> <li>[ ] Tests pass locally</li> <li>[ ] Documentation updated</li> <li>[ ] No console errors</li> <li>[ ] Followed code style</li> </ul>"},{"location":"CONTRIBUTING/#3-pr-requirements","title":"3. PR requirements","text":"<p>Before your PR can be merged: -  All commits follow conventional format (enforced by CI) -  All GitHub Actions checks pass -  Code review approved by @cadenlund -  All review comments resolved -  Branch is up to date with dev -  PR is focused (one feature/fix only)</p>"},{"location":"CONTRIBUTING/#4-after-approval","title":"4. After Approval","text":"<ul> <li>Only @cadenlund merges PRs</li> <li>GitHub will prompt to delete branch - click \"Delete branch\"</li> <li>Pull latest dev locally: git pull origin dev</li> </ul>"},{"location":"CONTRIBUTING/#5-pr-labels","title":"5. PR Labels","text":"<p>Add relevant labels: - feature - New functionality - bug - Bug fixes - documentation - Docs only - refactor - Code improvement - urgent - Needs quick review</p>"},{"location":"data_pipeline/overview/","title":"Data Pipeline Overview","text":"<p>Apache Airflow 2.10.4 pipeline for securities data ingestion.</p>"},{"location":"data_pipeline/overview/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    A[Airflow DAGs] --&gt; B[YfinancePipeline]\n    B --&gt; C[YfinanceClient]\n    C --&gt; D[(PostgreSQL + TimescaleDB)]\n\n    B --&gt; E[Scraping]\n    B --&gt; F[Validation]\n    C --&gt; G[Bulk Insert]</code></pre> <p>Performance</p> <p>Uses <code>psycopg2.extras.execute_values</code> for 10-100x faster bulk inserts</p>"},{"location":"data_pipeline/overview/#dags","title":"DAGs","text":""},{"location":"data_pipeline/overview/#historical-dag","title":"Historical DAG","text":"<p>Bulk data loading with parallel execution</p> <ul> <li>Trigger: Manual via Airflow UI</li> <li>Parallelism: 20 concurrent tasks</li> <li>Retries: 2-3 with exponential backoff</li> </ul>"},{"location":"data_pipeline/overview/#daily-dag","title":"Daily DAG","text":"<p>Incremental updates for existing securities</p> <ul> <li>Schedule: Weekdays 9:30 PM UTC</li> <li>Parallelism: 20 concurrent tasks</li> <li>Auto-runs: After market close</li> </ul>"},{"location":"data_pipeline/overview/#configuration","title":"Configuration","text":"Environment VariablePython <pre><code>SEC_MASTER_DB_URL=\"postgresql://user:pass@localhost:5432/sec_master_dev\"\n</code></pre> <pre><code>from utils.database import get_database_url\nclient = YfinanceClient(get_database_url())\n</code></pre>"},{"location":"data_pipeline/overview/#deployment","title":"Deployment","text":"<p>Quick Start</p> <pre><code>docker compose -f infrastructure/docker-compose.data-pipeline.yml up -d\n</code></pre> <p>Access Airflow: <code>http://localhost:8080</code> (admin/admin)</p>"},{"location":"data_pipeline/components/tickers/","title":"Ticker Scrapers","text":"<p>Methods for scraping ticker lists from public sources.</p>"},{"location":"data_pipeline/components/tickers/#sources","title":"Sources","text":""},{"location":"data_pipeline/components/tickers/#sp-500","title":"S&amp;P 500","text":"<ul> <li>Source: Wikipedia</li> <li>Count: ~500 tickers</li> <li>Cleaned: Replaces dots with dashes (BRK.B \u2192 BRK-B)</li> </ul>"},{"location":"data_pipeline/components/tickers/#russell-3000","title":"Russell 3000","text":"<ul> <li>Source: iShares IWV ETF holdings CSV</li> <li>Count: ~3000 tickers</li> <li>Filters: Removes CASH, USD, and symbols &gt;5 characters</li> </ul>"},{"location":"data_pipeline/components/tickers/#nasdaq","title":"NASDAQ","text":"<ul> <li>Source: NASDAQ Trader official list</li> <li>Count: ~3000+ tickers</li> <li>Filters: Removes test issues</li> </ul>"},{"location":"data_pipeline/components/tickers/#validation","title":"Validation","text":"<p>Each ticker is validated by attempting a 21-day test download. Valid tickers must return \u226510 trading days of data.</p>"},{"location":"data_pipeline/components/validation/","title":"Data Validation","text":"<p>Great Expectations validation framework for OHLCV data quality.</p>"},{"location":"data_pipeline/components/validation/#validation-process","title":"Validation Process","text":"<pre><code>sequenceDiagram\n    participant DAG as Airflow DAG\n    participant Pipeline as YfinancePipeline\n    participant GX as Great Expectations\n\n    DAG-&gt;&gt;Pipeline: validate_ohlcv(df, ticker)\n    Pipeline-&gt;&gt;GX: Run 18 checks\n    GX--&gt;&gt;Pipeline: Results\n    alt Validation Pass\n        Pipeline--&gt;&gt;DAG: Success\n    else Validation Fail\n        Pipeline--&gt;&gt;DAG: Raise Exception\n    end</code></pre>"},{"location":"data_pipeline/components/validation/#validation-checks","title":"Validation Checks","text":"<p>Schema Validation</p> <ul> <li>Required columns: Open, High, Low, Close, Volume</li> </ul> <p>Null Checks</p> <ul> <li>Zero tolerance for NaN/null values</li> </ul> <p>Price Logic</p> <ul> <li>High \u2265 Low</li> <li>Open/Close within High/Low range</li> <li>Prices &gt; $0.01</li> </ul> <p>Data Quality</p> <ul> <li>Standard deviation &gt; 0.01 (detects constant values)</li> <li>Minimum 10 rows</li> <li>Unique dates (no duplicates)</li> </ul> <p>Volume</p> <ul> <li>Non-negative (0 allowed)</li> </ul>"},{"location":"data_pipeline/components/validation/#constants","title":"Constants","text":"<p>Defined in <code>YfinancePipeline</code> class:</p> Constant Value Purpose <code>TICKER_VALIDATION_TEST_DAYS</code> 21 Calendar days for ticker test <code>MIN_TRADING_DAYS_FOR_VALIDATION</code> 10 Minimum trading days required <code>MIN_OHLCV_ROWS_FOR_VALIDATION</code> 10 Minimum rows for validation <code>MIN_PRICE_VALUE</code> 0.01 Minimum valid price <code>MIN_STDDEV_VALUE</code> 0.01 Minimum standard deviation <code>MAX_TICKER_LENGTH</code> 5 Maximum ticker symbol length"},{"location":"data_pipeline/components/validation/#error-handling","title":"Error Handling","text":"<p>Validation Failures</p> <p>Validation failures raise exceptions for Airflow to retry. Failed validations are logged with specific check names.</p> <p>Debugging</p> <p>Check Airflow task logs for detailed validation failure messages with check names and row counts.</p>"},{"location":"data_pipeline/components/yfinance_client/","title":"YfinanceClient API Reference","text":""},{"location":"data_pipeline/components/yfinance_client/#sec_master_db.clients.yfinance_client.YfinanceClient","title":"<code>sec_master_db.clients.yfinance_client.YfinanceClient</code>","text":"Source code in <code>data_pipeline/sec_master_db/clients/yfinance_client.py</code> <pre><code>class YfinanceClient:\n    def __init__(self, db_url: str):\n        \"\"\"\n        Initialize YfinanceClient for database operations.\n\n        Args:\n            db_url: PostgreSQL connection string. If None, uses SEC_MASTER_DB_URL_PROD env var\n                   or defaults to local dev database.\n\n        Example:\n            client = YfinanceClient(\"postgresql://user:pass@localhost:5432/sec_master_dev\")\n        \"\"\"\n        # Set up connection\n        self.engine = create_engine(db_url)\n        self.Session = sessionmaker(bind=self.engine)\n\n\n    # Security management methods    \n    def insert_security(self, ticker: str, groupings: List[str], provider: str = 'yfinance'):\n        \"\"\"\n        Insert a ticker symbol into the security_master.securities table.\n\n        Args:\n            ticker: Ticker symbol (e.g., 'AAPL')\n            groupings: List of grouping tags (e.g., ['sp500', 'tech', 'large-cap'])\n            provider: Data provider name (default: 'yfinance')\n\n        Returns:\n            dict: {\n                'success': bool,\n                'ticker': str,\n                'rows_affected': int,\n                'message': str\n            }\n\n        Raises:\n            Exception: If database insertion fails\n\n        Example:\n            result = client.insert_security('AAPL', ['sp500', 'nasdaq'])\n            if result['rows_affected'] &gt; 0:\n                print(\"Inserted successfully\")\n\n        Note:\n            Uses ON CONFLICT DO NOTHING, so duplicate tickers return rowcount=0.\n        \"\"\"\n\n        session = self.Session()\n\n        try:\n\n            # Insert a security\n            query = text(\"\"\"\n                INSERT INTO security_master.securities (ticker, provider, groupings, created_at)\n                VALUES (:ticker, :provider, :groupings, NOW())\n                ON CONFLICT (ticker, provider)\n                DO NOTHING\n            \"\"\")\n\n            # Execute query\n            result = session.execute(query, {'ticker': ticker, 'provider': provider, 'groupings': groupings})\n\n            # Get the number of affected rows\n            rows = getattr(result, 'rowcount', 0)\n\n            # Commit saves DB changes\n            session.commit()\n\n            # Return a formatted summary dict\n            return {\n                'success': True,\n                'ticker': ticker,\n                'rows_affected': rows,\n                'message': f\"Inserted {ticker}\" if rows &gt; 0 else f\"{ticker} already exists\"\n            }\n\n        # Catch Error\n        except Exception as e:\n            session.rollback()  # Important: rollback on error so we dont commit partial data\n            logger.error(f\"Failed to insert security {ticker}: {e}\")\n            raise Exception(f\"Security insertion failed for {ticker}: {str(e)}\") from e\n        finally:\n            session.close()\n\n    def get_security_id(self, ticker: str, provider: str = 'yfinance') -&gt; Optional[int]:\n        \"\"\"\n        Retrieve the unique security_id for a ticker symbol.\n\n        Args:\n            ticker: Ticker symbol (e.g., 'AAPL')\n            provider: Data provider name (default: 'yfinance')\n\n        Returns:\n            int: The security_id if found, None if ticker doesn't exist\n\n        Example:\n            security_id = client.get_security_id('AAPL')\n            if security_id:\n                print(f\"AAPL has ID: {security_id}\")\n\n        Note:\n            This ID is used as foreign key in OHLCV and metadata tables.\n        \"\"\"\n        session = self.Session()\n\n        try:\n            query = text(\"\"\"\n                SELECT security_id\n                FROM security_master.securities\n                WHERE ticker = :ticker AND provider = :provider\n            \"\"\")\n\n            # Execute SQL query\n            result = session.execute(query, {'ticker': ticker, 'provider': provider})\n\n            # Get the first row\n            row = result.fetchone()\n\n            # Return the security id\n            if not row:\n                raise ValueError(f\"Security ID not found for ticker {ticker} with provider {provider}\")\n            return row[0]\n\n        except Exception as e:\n            logger.error(f\"Failed to get security_id for {ticker}: {e}\")\n            raise Exception(f\"Failed to retrieve security_id for {ticker}: {str(e)}\") from e\n        finally:\n            session.close()\n\n    # Yfinance Schema storage\n    def insert_ohlcv(self, ticker: str, data: pd.DataFrame):\n        \"\"\"\n        Insert OHLCV (Open, High, Low, Close, Volume) data for a single ticker.\n\n        Args:\n            ticker: Ticker symbol (must exist in securities table)\n            data: DataFrame with columns: Date (index), Open, High, Low, Close, Volume\n                  Date can be either index or column.\n\n        Returns:\n            dict: {\n                'success': bool,\n                'ticker': str,\n                'rows_affected': int,\n                'message': str\n            }\n\n        Raises:\n            Exception: If ticker not found or insertion fails\n\n        Example:\n            import yfinance as yf\n            df = yf.download('AAPL', start='2024-01-01', end='2024-12-31')\n            result = client.insert_ohlcv('AAPL', df)\n            print(f\"Inserted/updated {result['rows_affected']} rows\")\n\n        Note:\n            Uses ON CONFLICT UPDATE to handle duplicate dates (updates existing records).\n        \"\"\"\n\n        session = self.Session()\n\n        try:\n            # Get security id \n            security_id = self.get_security_id(ticker)\n\n            # Prepare data as tuples for maximum performance\n            records = data.reset_index()\n\n            # Create list of tuples for execute_values (MUCH faster than execute_many)\n            insert_data = [\n                (\n                    security_id,\n                    row['Date'],\n                    float(row['Open']),\n                    float(row['High']),\n                    float(row['Low']),\n                    float(row['Close']),\n                    int(row['Volume'])\n                )\n                for _, row in records.iterrows()\n            ]\n\n            # Get the raw connection from SQLAlchemy session\n            raw_conn = session.connection().connection\n            cursor = raw_conn.cursor()\n\n            # Use execute_values with ON CONFLICT for bulk upsert (SUPER FAST!)\n            execute_values(\n                cursor,\n                \"\"\"\n                INSERT INTO yfinance.ohlcv_data\n                (security_id, date, open, high, low, close, volume)\n                VALUES %s\n                ON CONFLICT (security_id, date)\n                DO UPDATE SET\n                    open = EXCLUDED.open,\n                    high = EXCLUDED.high,\n                    low = EXCLUDED.low,\n                    close = EXCLUDED.close,\n                    volume = EXCLUDED.volume\n                \"\"\",\n                insert_data,\n                template=None,  # Use default template\n                page_size=1000  # Process 1000 rows at a time\n            )\n\n            # Get rows affected from cursor\n            rows = cursor.rowcount # row update/insert count\n\n            # Commit the changes\n            raw_conn.commit()\n            cursor.close()\n            return {\n                'success': True,\n                'ticker': ticker,\n                'rows_affected': rows,\n                'message': f\"Insert OHLCV for {ticker}\" if rows &gt; 0 else f\"{ticker} already in OHLCV DB\"\n            }\n\n        except Exception as e:\n            # Rollback both the raw connection and session\n            try:\n                raw_conn.rollback()\n            except:\n                pass\n            session.rollback()\n            logger.error(f\"Failed to insert OHLCV data for {ticker}: {e}\")\n            raise Exception(f\"OHLCV insertion failed for {ticker}: {str(e)}\") from e\n\n        finally:\n            session.close()\n\n\n\n\n    def insert_metadata(self, ticker: str, metadata: Dict):\n        \"\"\"\n        Insert comprehensive financial metadata for a ticker.\n\n        Args:\n            ticker: Ticker symbol (must exist in securities table)\n            metadata: Dictionary containing financial metrics. Expected keys include:\n                     - Company info: company_name, exchange, sector, industry, country\n                     - Valuation: market_cap, enterprise_value, price_to_book, forward_pe\n                     - Financials: gross_margin, operating_margin, profit_margin, debt_to_equity\n                     - Performance: beta, 52_week_high, 52_week_low, average_volume\n                     - And many more (see schema for full list)\n\n        Returns:\n            dict: {\n                'success': bool,\n                'ticker': str,\n                'rows_affected': int,\n                'message': str\n            }\n\n        Raises:\n            Exception: If ticker not found or insertion fails\n\n        Example:\n            metadata = pipeline.scrape_metadata(['AAPL'])\n            result = client.insert_metadata('AAPL', metadata['AAPL'])\n            print(f\"Rows affected: {result['rows_affected']}\")\n\n        Note:\n            Missing keys are stored as NULL. Uses ON CONFLICT UPDATE for existing records.\n        \"\"\"\n        session = self.Session()\n\n        try:\n            # Get security_id\n            security_id = self.get_security_id(ticker)\n\n            if not security_id:\n                raise Exception(f\"No security id for ticker: {ticker}\")\n\n            # Build the INSERT query with all columns\n            query = text(\"\"\"\n                INSERT INTO yfinance.stock_metadata (\n                    security_id, date_scraped,\n                    -- Company Basic Info\n                    company_name, exchange, country, sector, industry,\n                    market_cap, enterprise_value, shares_outstanding, float_shares,\n                    -- Valuation Metrics\n                    price_to_book, forward_pe, ev_to_ebitda, ev_to_revenue, price_to_sales,\n                    -- Profitability &amp; Quality\n                    gross_margin, operating_margin, profit_margin,\n                    return_on_equity, return_on_assets, free_cash_flow_yield,\n                    -- Growth Metrics\n                    revenue_growth_yoy, revenue_per_share,\n                    -- Financial Health\n                    debt_to_equity, current_ratio, quick_ratio,\n                    total_cash, total_debt, total_cash_per_share, book_value,\n                    -- Cash Flow\n                    operating_cash_flow, free_cash_flow,\n                    -- Dividends\n                    payout_ratio,\n                    -- Short Interest &amp; Ownership\n                    short_percent_of_float, short_ratio, shares_short,\n                    shares_percent_shares_out, held_percent_institutions, held_percent_insiders,\n                    -- Analyst Coverage\n                    target_mean_price, target_price_upside, number_of_analysts, recommendation_key,\n                    -- Market Performance\n                    beta, fifty_two_week_high, fifty_two_week_low,\n                    fifty_two_week_change, sp500_52_week_change,\n                    fifty_day_average, two_hundred_day_average,\n                    -- Trading Volume\n                    average_volume, average_volume_10days, regular_market_volume,\n                    -- Metadata\n                    data_source\n                )\n                VALUES (\n                    :security_id, :date_scraped,\n                    -- Company Basic Info\n                    :company_name, :exchange, :country, :sector, :industry,\n                    :market_cap, :enterprise_value, :shares_outstanding, :float_shares,\n                    -- Valuation Metrics\n                    :price_to_book, :forward_pe, :ev_to_ebitda, :ev_to_revenue, :price_to_sales,\n                    -- Profitability &amp; Quality\n                    :gross_margin, :operating_margin, :profit_margin,\n                    :return_on_equity, :return_on_assets, :free_cash_flow_yield,\n                    -- Growth Metrics\n                    :revenue_growth_yoy, :revenue_per_share,\n                    -- Financial Health\n                    :debt_to_equity, :current_ratio, :quick_ratio,\n                    :total_cash, :total_debt, :total_cash_per_share, :book_value,\n                    -- Cash Flow\n                    :operating_cash_flow, :free_cash_flow,\n                    -- Dividends\n                    :payout_ratio,\n                    -- Short Interest &amp; Ownership\n                    :short_percent_of_float, :short_ratio, :shares_short,\n                    :shares_percent_shares_out, :held_percent_institutions, :held_percent_insiders,\n                    -- Analyst Coverage\n                    :target_mean_price, :target_price_upside, :number_of_analysts, :recommendation_key,\n                    -- Market Performance\n                    :beta, :fifty_two_week_high, :fifty_two_week_low,\n                    :fifty_two_week_change, :sp500_52_week_change,\n                    :fifty_day_average, :two_hundred_day_average,\n                    -- Trading Volume\n                    :average_volume, :average_volume_10days, :regular_market_volume,\n                    -- Metadata\n                    :data_source\n                )\n                ON CONFLICT (security_id, date_scraped)\n                DO UPDATE SET\n                    company_name = EXCLUDED.company_name,\n                    exchange = EXCLUDED.exchange,\n                    country = EXCLUDED.country,\n                    sector = EXCLUDED.sector,\n                    industry = EXCLUDED.industry,\n                    market_cap = EXCLUDED.market_cap,\n                    enterprise_value = EXCLUDED.enterprise_value,\n                    shares_outstanding = EXCLUDED.shares_outstanding,\n                    float_shares = EXCLUDED.float_shares,\n                    price_to_book = EXCLUDED.price_to_book,\n                    forward_pe = EXCLUDED.forward_pe,\n                    ev_to_ebitda = EXCLUDED.ev_to_ebitda,\n                    ev_to_revenue = EXCLUDED.ev_to_revenue,\n                    price_to_sales = EXCLUDED.price_to_sales,\n                    gross_margin = EXCLUDED.gross_margin,\n                    operating_margin = EXCLUDED.operating_margin,\n                    profit_margin = EXCLUDED.profit_margin,\n                    return_on_equity = EXCLUDED.return_on_equity,\n                    return_on_assets = EXCLUDED.return_on_assets,\n                    free_cash_flow_yield = EXCLUDED.free_cash_flow_yield,\n                    revenue_growth_yoy = EXCLUDED.revenue_growth_yoy,\n                    revenue_per_share = EXCLUDED.revenue_per_share,\n                    debt_to_equity = EXCLUDED.debt_to_equity,\n                    current_ratio = EXCLUDED.current_ratio,\n                    quick_ratio = EXCLUDED.quick_ratio,\n                    total_cash = EXCLUDED.total_cash,\n                    total_debt = EXCLUDED.total_debt,\n                    total_cash_per_share = EXCLUDED.total_cash_per_share,\n                    book_value = EXCLUDED.book_value,\n                    operating_cash_flow = EXCLUDED.operating_cash_flow,\n                    free_cash_flow = EXCLUDED.free_cash_flow,\n                    payout_ratio = EXCLUDED.payout_ratio,\n                    short_percent_of_float = EXCLUDED.short_percent_of_float,\n                    short_ratio = EXCLUDED.short_ratio,\n                    shares_short = EXCLUDED.shares_short,\n                    shares_percent_shares_out = EXCLUDED.shares_percent_shares_out,\n                    held_percent_institutions = EXCLUDED.held_percent_institutions,\n                    held_percent_insiders = EXCLUDED.held_percent_insiders,\n                    target_mean_price = EXCLUDED.target_mean_price,\n                    target_price_upside = EXCLUDED.target_price_upside,\n                    number_of_analysts = EXCLUDED.number_of_analysts,\n                    recommendation_key = EXCLUDED.recommendation_key,\n                    beta = EXCLUDED.beta,\n                    fifty_two_week_high = EXCLUDED.fifty_two_week_high,\n                    fifty_two_week_low = EXCLUDED.fifty_two_week_low,\n                    fifty_two_week_change = EXCLUDED.fifty_two_week_change,\n                    sp500_52_week_change = EXCLUDED.sp500_52_week_change,\n                    fifty_day_average = EXCLUDED.fifty_day_average,\n                    two_hundred_day_average = EXCLUDED.two_hundred_day_average,\n                    average_volume = EXCLUDED.average_volume,\n                    average_volume_10days = EXCLUDED.average_volume_10days,\n                    regular_market_volume = EXCLUDED.regular_market_volume,\n                    last_updated = CURRENT_TIMESTAMP\n            \"\"\")\n\n            # Map metadata dict keys to database columns\n            params = {\n                'security_id': security_id,\n                'date_scraped': metadata.get('date_scraped'),\n                'company_name': metadata.get('company_name'),\n                'exchange': metadata.get('exchange'),\n                'country': metadata.get('country'),\n                'sector': metadata.get('sector'),\n                'industry': metadata.get('industry'),\n                'market_cap': metadata.get('market_cap'),\n                'enterprise_value': metadata.get('enterprise_value'),\n                'shares_outstanding': metadata.get('shares_outstanding'),\n                'float_shares': metadata.get('float_shares'),\n                'price_to_book': metadata.get('price_to_book'),\n                'forward_pe': metadata.get('forward_pe'),\n                'ev_to_ebitda': metadata.get('ev_to_ebitda'),\n                'ev_to_revenue': metadata.get('ev_to_revenue'),\n                'price_to_sales': metadata.get('price_to_sales'),\n                'gross_margin': metadata.get('gross_margin'),\n                'operating_margin': metadata.get('operating_margin'),\n                'profit_margin': metadata.get('profit_margin'),\n                'return_on_equity': metadata.get('return_on_equity'),\n                'return_on_assets': metadata.get('return_on_assets'),\n                'free_cash_flow_yield': metadata.get('free_cash_flow_yield'),\n                'revenue_growth_yoy': metadata.get('revenue_growth_yoy'),\n                'revenue_per_share': metadata.get('revenue_per_share'),\n                'debt_to_equity': metadata.get('debt_to_equity'),\n                'current_ratio': metadata.get('current_ratio'),\n                'quick_ratio': metadata.get('quick_ratio'),\n                'total_cash': metadata.get('total_cash'),\n                'total_debt': metadata.get('total_debt'),\n                'total_cash_per_share': metadata.get('total_cash_per_share'),\n                'book_value': metadata.get('book_value'),\n                'operating_cash_flow': metadata.get('operating_cash_flow'),\n                'free_cash_flow': metadata.get('free_cash_flow'),\n                'payout_ratio': metadata.get('payout_ratio'),\n                'short_percent_of_float': metadata.get('short_percent_of_float'),\n                'short_ratio': metadata.get('short_ratio'),\n                'shares_short': metadata.get('shares_short'),\n                'shares_percent_shares_out': metadata.get('shares_percent_shares_out'),\n                'held_percent_institutions': metadata.get('held_percent_institutions'),\n                'held_percent_insiders': metadata.get('held_percent_insiders'),\n                'target_mean_price': metadata.get('target_mean_price'),\n                'target_price_upside': metadata.get('target_price_upside'),\n                'number_of_analysts': metadata.get('number_of_analysts'),\n                'recommendation_key': metadata.get('recommendation_key'),\n                'beta': metadata.get('beta'),\n                # Note: scraper uses '52_week_high' but DB uses 'fifty_two_week_high'\n                'fifty_two_week_high': metadata.get('52_week_high'),\n                'fifty_two_week_low': metadata.get('52_week_low'),\n                'fifty_two_week_change': metadata.get('52_week_change'),\n                'sp500_52_week_change': metadata.get('sp500_52_week_change'),\n                'fifty_day_average': metadata.get('50_day_average'),\n                'two_hundred_day_average': metadata.get('200_day_average'),\n                'average_volume': metadata.get('average_volume'),\n                'average_volume_10days': metadata.get('average_volume_10days'),\n                'regular_market_volume': metadata.get('regular_market_volume'),\n                'data_source': metadata.get('data_source', 'yfinance')\n            }\n\n            # Execute the query\n            result = session.execute(query, params)\n\n            # Get the number of affected rows\n            rows = getattr(result, 'rowcount', 0)\n\n            session.commit()\n            return {\n                'success': True,\n                'ticker': ticker,\n                'rows_affected': rows,\n                'message': f\"Inserted metadata for {ticker}\" if rows &gt; 0 else f\"{ticker} already exists in metadata DB\"\n            }\n\n        except Exception as e:\n            session.rollback()\n            logger.error(f\"Failed to insert metadata for {ticker}: {e}\")\n            raise Exception(f\"Metadata insertion failed for {ticker}: {str(e)}\") from e\n        finally:\n            session.close()\n\n    def get_tickers(self, groupings: Optional[List[str]] = None, provider: str = 'yfinance') -&gt; List[str]:\n        \"\"\"\n        Get tickers from database, optionally filtered by groupings\n\n        Args:\n            groupings: Optional list of groupings to filter by (e.g., ['sp500', 'nasdaq'])\n                      If None, returns all tickers for the provider\n            provider: Data provider (default: 'yfinance')\n\n        Returns:\n            List of ticker symbols\n\n        Examples:\n            # Get all tickers\n            all_tickers = client.get_tickers()\n\n            # Get S&amp;P 500 tickers\n            sp500 = client.get_tickers(['sp500'])\n\n            # Get both S&amp;P 500 and NASDAQ tickers\n            combined = client.get_tickers(['sp500', 'nasdaq'])\n        \"\"\"\n        session = self.Session()\n\n        try:\n            if groupings:\n\n                # Get tickers that have ANY of the specified groupings\n                query = text(\"\"\"\n                    SELECT DISTINCT ticker\n                    FROM security_master.securities\n                    WHERE provider = :provider\n                    AND groupings &amp;&amp; :groupings_array  -- Array overlap operator\n                    ORDER BY ticker\n                \"\"\")\n\n                result = session.execute(query, {\n                    'provider': provider,\n                    'groupings_array': groupings\n                })\n            else:\n\n                # Select all\n                query = text(\"\"\"\n                    SELECT ticker\n                    FROM security_master.securities\n                    WHERE provider = :provider\n                    ORDER BY ticker\n                \"\"\")\n\n                result = session.execute(query, {'provider': provider})\n\n            # Fetch tickers from result\n            tickers = [row[0] for row in result.fetchall()]\n            return tickers\n\n        except Exception as e:\n            logger.error(f\"Failed to get tickers from database: {e}\")\n            raise Exception(f\"Failed to retrieve tickers: {str(e)}\") from e\n        finally:\n            session.close()\n</code></pre>"},{"location":"data_pipeline/components/yfinance_client/#sec_master_db.clients.yfinance_client.YfinanceClient.__init__","title":"<code>__init__(db_url)</code>","text":"<p>Initialize YfinanceClient for database operations.</p> <p>Parameters:</p> Name Type Description Default <code>db_url</code> <code>str</code> <p>PostgreSQL connection string. If None, uses SEC_MASTER_DB_URL_PROD env var    or defaults to local dev database.</p> required Example <p>client = YfinanceClient(\"postgresql://user:pass@localhost:5432/sec_master_dev\")</p> Source code in <code>data_pipeline/sec_master_db/clients/yfinance_client.py</code> <pre><code>def __init__(self, db_url: str):\n    \"\"\"\n    Initialize YfinanceClient for database operations.\n\n    Args:\n        db_url: PostgreSQL connection string. If None, uses SEC_MASTER_DB_URL_PROD env var\n               or defaults to local dev database.\n\n    Example:\n        client = YfinanceClient(\"postgresql://user:pass@localhost:5432/sec_master_dev\")\n    \"\"\"\n    # Set up connection\n    self.engine = create_engine(db_url)\n    self.Session = sessionmaker(bind=self.engine)\n</code></pre>"},{"location":"data_pipeline/components/yfinance_client/#sec_master_db.clients.yfinance_client.YfinanceClient.get_security_id","title":"<code>get_security_id(ticker, provider='yfinance')</code>","text":"<p>Retrieve the unique security_id for a ticker symbol.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol (e.g., 'AAPL')</p> required <code>provider</code> <code>str</code> <p>Data provider name (default: 'yfinance')</p> <code>'yfinance'</code> <p>Returns:</p> Name Type Description <code>int</code> <code>Optional[int]</code> <p>The security_id if found, None if ticker doesn't exist</p> Example <p>security_id = client.get_security_id('AAPL') if security_id:     print(f\"AAPL has ID: {security_id}\")</p> Note <p>This ID is used as foreign key in OHLCV and metadata tables.</p> Source code in <code>data_pipeline/sec_master_db/clients/yfinance_client.py</code> <pre><code>def get_security_id(self, ticker: str, provider: str = 'yfinance') -&gt; Optional[int]:\n    \"\"\"\n    Retrieve the unique security_id for a ticker symbol.\n\n    Args:\n        ticker: Ticker symbol (e.g., 'AAPL')\n        provider: Data provider name (default: 'yfinance')\n\n    Returns:\n        int: The security_id if found, None if ticker doesn't exist\n\n    Example:\n        security_id = client.get_security_id('AAPL')\n        if security_id:\n            print(f\"AAPL has ID: {security_id}\")\n\n    Note:\n        This ID is used as foreign key in OHLCV and metadata tables.\n    \"\"\"\n    session = self.Session()\n\n    try:\n        query = text(\"\"\"\n            SELECT security_id\n            FROM security_master.securities\n            WHERE ticker = :ticker AND provider = :provider\n        \"\"\")\n\n        # Execute SQL query\n        result = session.execute(query, {'ticker': ticker, 'provider': provider})\n\n        # Get the first row\n        row = result.fetchone()\n\n        # Return the security id\n        if not row:\n            raise ValueError(f\"Security ID not found for ticker {ticker} with provider {provider}\")\n        return row[0]\n\n    except Exception as e:\n        logger.error(f\"Failed to get security_id for {ticker}: {e}\")\n        raise Exception(f\"Failed to retrieve security_id for {ticker}: {str(e)}\") from e\n    finally:\n        session.close()\n</code></pre>"},{"location":"data_pipeline/components/yfinance_client/#sec_master_db.clients.yfinance_client.YfinanceClient.get_tickers","title":"<code>get_tickers(groupings=None, provider='yfinance')</code>","text":"<p>Get tickers from database, optionally filtered by groupings</p> <p>Parameters:</p> Name Type Description Default <code>groupings</code> <code>Optional[List[str]]</code> <p>Optional list of groupings to filter by (e.g., ['sp500', 'nasdaq'])       If None, returns all tickers for the provider</p> <code>None</code> <code>provider</code> <code>str</code> <p>Data provider (default: 'yfinance')</p> <code>'yfinance'</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of ticker symbols</p> <p>Examples:</p>"},{"location":"data_pipeline/components/yfinance_client/#sec_master_db.clients.yfinance_client.YfinanceClient.get_tickers--get-all-tickers","title":"Get all tickers","text":"<p>all_tickers = client.get_tickers()</p>"},{"location":"data_pipeline/components/yfinance_client/#sec_master_db.clients.yfinance_client.YfinanceClient.get_tickers--get-sp-500-tickers","title":"Get S&amp;P 500 tickers","text":"<p>sp500 = client.get_tickers(['sp500'])</p>"},{"location":"data_pipeline/components/yfinance_client/#sec_master_db.clients.yfinance_client.YfinanceClient.get_tickers--get-both-sp-500-and-nasdaq-tickers","title":"Get both S&amp;P 500 and NASDAQ tickers","text":"<p>combined = client.get_tickers(['sp500', 'nasdaq'])</p> Source code in <code>data_pipeline/sec_master_db/clients/yfinance_client.py</code> <pre><code>def get_tickers(self, groupings: Optional[List[str]] = None, provider: str = 'yfinance') -&gt; List[str]:\n    \"\"\"\n    Get tickers from database, optionally filtered by groupings\n\n    Args:\n        groupings: Optional list of groupings to filter by (e.g., ['sp500', 'nasdaq'])\n                  If None, returns all tickers for the provider\n        provider: Data provider (default: 'yfinance')\n\n    Returns:\n        List of ticker symbols\n\n    Examples:\n        # Get all tickers\n        all_tickers = client.get_tickers()\n\n        # Get S&amp;P 500 tickers\n        sp500 = client.get_tickers(['sp500'])\n\n        # Get both S&amp;P 500 and NASDAQ tickers\n        combined = client.get_tickers(['sp500', 'nasdaq'])\n    \"\"\"\n    session = self.Session()\n\n    try:\n        if groupings:\n\n            # Get tickers that have ANY of the specified groupings\n            query = text(\"\"\"\n                SELECT DISTINCT ticker\n                FROM security_master.securities\n                WHERE provider = :provider\n                AND groupings &amp;&amp; :groupings_array  -- Array overlap operator\n                ORDER BY ticker\n            \"\"\")\n\n            result = session.execute(query, {\n                'provider': provider,\n                'groupings_array': groupings\n            })\n        else:\n\n            # Select all\n            query = text(\"\"\"\n                SELECT ticker\n                FROM security_master.securities\n                WHERE provider = :provider\n                ORDER BY ticker\n            \"\"\")\n\n            result = session.execute(query, {'provider': provider})\n\n        # Fetch tickers from result\n        tickers = [row[0] for row in result.fetchall()]\n        return tickers\n\n    except Exception as e:\n        logger.error(f\"Failed to get tickers from database: {e}\")\n        raise Exception(f\"Failed to retrieve tickers: {str(e)}\") from e\n    finally:\n        session.close()\n</code></pre>"},{"location":"data_pipeline/components/yfinance_client/#sec_master_db.clients.yfinance_client.YfinanceClient.insert_metadata","title":"<code>insert_metadata(ticker, metadata)</code>","text":"<p>Insert comprehensive financial metadata for a ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol (must exist in securities table)</p> required <code>metadata</code> <code>Dict</code> <p>Dictionary containing financial metrics. Expected keys include:      - Company info: company_name, exchange, sector, industry, country      - Valuation: market_cap, enterprise_value, price_to_book, forward_pe      - Financials: gross_margin, operating_margin, profit_margin, debt_to_equity      - Performance: beta, 52_week_high, 52_week_low, average_volume      - And many more (see schema for full list)</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>{ 'success': bool, 'ticker': str, 'rows_affected': int, 'message': str</p> <p>}</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If ticker not found or insertion fails</p> Example <p>metadata = pipeline.scrape_metadata(['AAPL']) result = client.insert_metadata('AAPL', metadata['AAPL']) print(f\"Rows affected: {result['rows_affected']}\")</p> Note <p>Missing keys are stored as NULL. Uses ON CONFLICT UPDATE for existing records.</p> Source code in <code>data_pipeline/sec_master_db/clients/yfinance_client.py</code> <pre><code>def insert_metadata(self, ticker: str, metadata: Dict):\n    \"\"\"\n    Insert comprehensive financial metadata for a ticker.\n\n    Args:\n        ticker: Ticker symbol (must exist in securities table)\n        metadata: Dictionary containing financial metrics. Expected keys include:\n                 - Company info: company_name, exchange, sector, industry, country\n                 - Valuation: market_cap, enterprise_value, price_to_book, forward_pe\n                 - Financials: gross_margin, operating_margin, profit_margin, debt_to_equity\n                 - Performance: beta, 52_week_high, 52_week_low, average_volume\n                 - And many more (see schema for full list)\n\n    Returns:\n        dict: {\n            'success': bool,\n            'ticker': str,\n            'rows_affected': int,\n            'message': str\n        }\n\n    Raises:\n        Exception: If ticker not found or insertion fails\n\n    Example:\n        metadata = pipeline.scrape_metadata(['AAPL'])\n        result = client.insert_metadata('AAPL', metadata['AAPL'])\n        print(f\"Rows affected: {result['rows_affected']}\")\n\n    Note:\n        Missing keys are stored as NULL. Uses ON CONFLICT UPDATE for existing records.\n    \"\"\"\n    session = self.Session()\n\n    try:\n        # Get security_id\n        security_id = self.get_security_id(ticker)\n\n        if not security_id:\n            raise Exception(f\"No security id for ticker: {ticker}\")\n\n        # Build the INSERT query with all columns\n        query = text(\"\"\"\n            INSERT INTO yfinance.stock_metadata (\n                security_id, date_scraped,\n                -- Company Basic Info\n                company_name, exchange, country, sector, industry,\n                market_cap, enterprise_value, shares_outstanding, float_shares,\n                -- Valuation Metrics\n                price_to_book, forward_pe, ev_to_ebitda, ev_to_revenue, price_to_sales,\n                -- Profitability &amp; Quality\n                gross_margin, operating_margin, profit_margin,\n                return_on_equity, return_on_assets, free_cash_flow_yield,\n                -- Growth Metrics\n                revenue_growth_yoy, revenue_per_share,\n                -- Financial Health\n                debt_to_equity, current_ratio, quick_ratio,\n                total_cash, total_debt, total_cash_per_share, book_value,\n                -- Cash Flow\n                operating_cash_flow, free_cash_flow,\n                -- Dividends\n                payout_ratio,\n                -- Short Interest &amp; Ownership\n                short_percent_of_float, short_ratio, shares_short,\n                shares_percent_shares_out, held_percent_institutions, held_percent_insiders,\n                -- Analyst Coverage\n                target_mean_price, target_price_upside, number_of_analysts, recommendation_key,\n                -- Market Performance\n                beta, fifty_two_week_high, fifty_two_week_low,\n                fifty_two_week_change, sp500_52_week_change,\n                fifty_day_average, two_hundred_day_average,\n                -- Trading Volume\n                average_volume, average_volume_10days, regular_market_volume,\n                -- Metadata\n                data_source\n            )\n            VALUES (\n                :security_id, :date_scraped,\n                -- Company Basic Info\n                :company_name, :exchange, :country, :sector, :industry,\n                :market_cap, :enterprise_value, :shares_outstanding, :float_shares,\n                -- Valuation Metrics\n                :price_to_book, :forward_pe, :ev_to_ebitda, :ev_to_revenue, :price_to_sales,\n                -- Profitability &amp; Quality\n                :gross_margin, :operating_margin, :profit_margin,\n                :return_on_equity, :return_on_assets, :free_cash_flow_yield,\n                -- Growth Metrics\n                :revenue_growth_yoy, :revenue_per_share,\n                -- Financial Health\n                :debt_to_equity, :current_ratio, :quick_ratio,\n                :total_cash, :total_debt, :total_cash_per_share, :book_value,\n                -- Cash Flow\n                :operating_cash_flow, :free_cash_flow,\n                -- Dividends\n                :payout_ratio,\n                -- Short Interest &amp; Ownership\n                :short_percent_of_float, :short_ratio, :shares_short,\n                :shares_percent_shares_out, :held_percent_institutions, :held_percent_insiders,\n                -- Analyst Coverage\n                :target_mean_price, :target_price_upside, :number_of_analysts, :recommendation_key,\n                -- Market Performance\n                :beta, :fifty_two_week_high, :fifty_two_week_low,\n                :fifty_two_week_change, :sp500_52_week_change,\n                :fifty_day_average, :two_hundred_day_average,\n                -- Trading Volume\n                :average_volume, :average_volume_10days, :regular_market_volume,\n                -- Metadata\n                :data_source\n            )\n            ON CONFLICT (security_id, date_scraped)\n            DO UPDATE SET\n                company_name = EXCLUDED.company_name,\n                exchange = EXCLUDED.exchange,\n                country = EXCLUDED.country,\n                sector = EXCLUDED.sector,\n                industry = EXCLUDED.industry,\n                market_cap = EXCLUDED.market_cap,\n                enterprise_value = EXCLUDED.enterprise_value,\n                shares_outstanding = EXCLUDED.shares_outstanding,\n                float_shares = EXCLUDED.float_shares,\n                price_to_book = EXCLUDED.price_to_book,\n                forward_pe = EXCLUDED.forward_pe,\n                ev_to_ebitda = EXCLUDED.ev_to_ebitda,\n                ev_to_revenue = EXCLUDED.ev_to_revenue,\n                price_to_sales = EXCLUDED.price_to_sales,\n                gross_margin = EXCLUDED.gross_margin,\n                operating_margin = EXCLUDED.operating_margin,\n                profit_margin = EXCLUDED.profit_margin,\n                return_on_equity = EXCLUDED.return_on_equity,\n                return_on_assets = EXCLUDED.return_on_assets,\n                free_cash_flow_yield = EXCLUDED.free_cash_flow_yield,\n                revenue_growth_yoy = EXCLUDED.revenue_growth_yoy,\n                revenue_per_share = EXCLUDED.revenue_per_share,\n                debt_to_equity = EXCLUDED.debt_to_equity,\n                current_ratio = EXCLUDED.current_ratio,\n                quick_ratio = EXCLUDED.quick_ratio,\n                total_cash = EXCLUDED.total_cash,\n                total_debt = EXCLUDED.total_debt,\n                total_cash_per_share = EXCLUDED.total_cash_per_share,\n                book_value = EXCLUDED.book_value,\n                operating_cash_flow = EXCLUDED.operating_cash_flow,\n                free_cash_flow = EXCLUDED.free_cash_flow,\n                payout_ratio = EXCLUDED.payout_ratio,\n                short_percent_of_float = EXCLUDED.short_percent_of_float,\n                short_ratio = EXCLUDED.short_ratio,\n                shares_short = EXCLUDED.shares_short,\n                shares_percent_shares_out = EXCLUDED.shares_percent_shares_out,\n                held_percent_institutions = EXCLUDED.held_percent_institutions,\n                held_percent_insiders = EXCLUDED.held_percent_insiders,\n                target_mean_price = EXCLUDED.target_mean_price,\n                target_price_upside = EXCLUDED.target_price_upside,\n                number_of_analysts = EXCLUDED.number_of_analysts,\n                recommendation_key = EXCLUDED.recommendation_key,\n                beta = EXCLUDED.beta,\n                fifty_two_week_high = EXCLUDED.fifty_two_week_high,\n                fifty_two_week_low = EXCLUDED.fifty_two_week_low,\n                fifty_two_week_change = EXCLUDED.fifty_two_week_change,\n                sp500_52_week_change = EXCLUDED.sp500_52_week_change,\n                fifty_day_average = EXCLUDED.fifty_day_average,\n                two_hundred_day_average = EXCLUDED.two_hundred_day_average,\n                average_volume = EXCLUDED.average_volume,\n                average_volume_10days = EXCLUDED.average_volume_10days,\n                regular_market_volume = EXCLUDED.regular_market_volume,\n                last_updated = CURRENT_TIMESTAMP\n        \"\"\")\n\n        # Map metadata dict keys to database columns\n        params = {\n            'security_id': security_id,\n            'date_scraped': metadata.get('date_scraped'),\n            'company_name': metadata.get('company_name'),\n            'exchange': metadata.get('exchange'),\n            'country': metadata.get('country'),\n            'sector': metadata.get('sector'),\n            'industry': metadata.get('industry'),\n            'market_cap': metadata.get('market_cap'),\n            'enterprise_value': metadata.get('enterprise_value'),\n            'shares_outstanding': metadata.get('shares_outstanding'),\n            'float_shares': metadata.get('float_shares'),\n            'price_to_book': metadata.get('price_to_book'),\n            'forward_pe': metadata.get('forward_pe'),\n            'ev_to_ebitda': metadata.get('ev_to_ebitda'),\n            'ev_to_revenue': metadata.get('ev_to_revenue'),\n            'price_to_sales': metadata.get('price_to_sales'),\n            'gross_margin': metadata.get('gross_margin'),\n            'operating_margin': metadata.get('operating_margin'),\n            'profit_margin': metadata.get('profit_margin'),\n            'return_on_equity': metadata.get('return_on_equity'),\n            'return_on_assets': metadata.get('return_on_assets'),\n            'free_cash_flow_yield': metadata.get('free_cash_flow_yield'),\n            'revenue_growth_yoy': metadata.get('revenue_growth_yoy'),\n            'revenue_per_share': metadata.get('revenue_per_share'),\n            'debt_to_equity': metadata.get('debt_to_equity'),\n            'current_ratio': metadata.get('current_ratio'),\n            'quick_ratio': metadata.get('quick_ratio'),\n            'total_cash': metadata.get('total_cash'),\n            'total_debt': metadata.get('total_debt'),\n            'total_cash_per_share': metadata.get('total_cash_per_share'),\n            'book_value': metadata.get('book_value'),\n            'operating_cash_flow': metadata.get('operating_cash_flow'),\n            'free_cash_flow': metadata.get('free_cash_flow'),\n            'payout_ratio': metadata.get('payout_ratio'),\n            'short_percent_of_float': metadata.get('short_percent_of_float'),\n            'short_ratio': metadata.get('short_ratio'),\n            'shares_short': metadata.get('shares_short'),\n            'shares_percent_shares_out': metadata.get('shares_percent_shares_out'),\n            'held_percent_institutions': metadata.get('held_percent_institutions'),\n            'held_percent_insiders': metadata.get('held_percent_insiders'),\n            'target_mean_price': metadata.get('target_mean_price'),\n            'target_price_upside': metadata.get('target_price_upside'),\n            'number_of_analysts': metadata.get('number_of_analysts'),\n            'recommendation_key': metadata.get('recommendation_key'),\n            'beta': metadata.get('beta'),\n            # Note: scraper uses '52_week_high' but DB uses 'fifty_two_week_high'\n            'fifty_two_week_high': metadata.get('52_week_high'),\n            'fifty_two_week_low': metadata.get('52_week_low'),\n            'fifty_two_week_change': metadata.get('52_week_change'),\n            'sp500_52_week_change': metadata.get('sp500_52_week_change'),\n            'fifty_day_average': metadata.get('50_day_average'),\n            'two_hundred_day_average': metadata.get('200_day_average'),\n            'average_volume': metadata.get('average_volume'),\n            'average_volume_10days': metadata.get('average_volume_10days'),\n            'regular_market_volume': metadata.get('regular_market_volume'),\n            'data_source': metadata.get('data_source', 'yfinance')\n        }\n\n        # Execute the query\n        result = session.execute(query, params)\n\n        # Get the number of affected rows\n        rows = getattr(result, 'rowcount', 0)\n\n        session.commit()\n        return {\n            'success': True,\n            'ticker': ticker,\n            'rows_affected': rows,\n            'message': f\"Inserted metadata for {ticker}\" if rows &gt; 0 else f\"{ticker} already exists in metadata DB\"\n        }\n\n    except Exception as e:\n        session.rollback()\n        logger.error(f\"Failed to insert metadata for {ticker}: {e}\")\n        raise Exception(f\"Metadata insertion failed for {ticker}: {str(e)}\") from e\n    finally:\n        session.close()\n</code></pre>"},{"location":"data_pipeline/components/yfinance_client/#sec_master_db.clients.yfinance_client.YfinanceClient.insert_ohlcv","title":"<code>insert_ohlcv(ticker, data)</code>","text":"<p>Insert OHLCV (Open, High, Low, Close, Volume) data for a single ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol (must exist in securities table)</p> required <code>data</code> <code>DataFrame</code> <p>DataFrame with columns: Date (index), Open, High, Low, Close, Volume   Date can be either index or column.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>{ 'success': bool, 'ticker': str, 'rows_affected': int, 'message': str</p> <p>}</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If ticker not found or insertion fails</p> Example <p>import yfinance as yf df = yf.download('AAPL', start='2024-01-01', end='2024-12-31') result = client.insert_ohlcv('AAPL', df) print(f\"Inserted/updated {result['rows_affected']} rows\")</p> Note <p>Uses ON CONFLICT UPDATE to handle duplicate dates (updates existing records).</p> Source code in <code>data_pipeline/sec_master_db/clients/yfinance_client.py</code> <pre><code>def insert_ohlcv(self, ticker: str, data: pd.DataFrame):\n    \"\"\"\n    Insert OHLCV (Open, High, Low, Close, Volume) data for a single ticker.\n\n    Args:\n        ticker: Ticker symbol (must exist in securities table)\n        data: DataFrame with columns: Date (index), Open, High, Low, Close, Volume\n              Date can be either index or column.\n\n    Returns:\n        dict: {\n            'success': bool,\n            'ticker': str,\n            'rows_affected': int,\n            'message': str\n        }\n\n    Raises:\n        Exception: If ticker not found or insertion fails\n\n    Example:\n        import yfinance as yf\n        df = yf.download('AAPL', start='2024-01-01', end='2024-12-31')\n        result = client.insert_ohlcv('AAPL', df)\n        print(f\"Inserted/updated {result['rows_affected']} rows\")\n\n    Note:\n        Uses ON CONFLICT UPDATE to handle duplicate dates (updates existing records).\n    \"\"\"\n\n    session = self.Session()\n\n    try:\n        # Get security id \n        security_id = self.get_security_id(ticker)\n\n        # Prepare data as tuples for maximum performance\n        records = data.reset_index()\n\n        # Create list of tuples for execute_values (MUCH faster than execute_many)\n        insert_data = [\n            (\n                security_id,\n                row['Date'],\n                float(row['Open']),\n                float(row['High']),\n                float(row['Low']),\n                float(row['Close']),\n                int(row['Volume'])\n            )\n            for _, row in records.iterrows()\n        ]\n\n        # Get the raw connection from SQLAlchemy session\n        raw_conn = session.connection().connection\n        cursor = raw_conn.cursor()\n\n        # Use execute_values with ON CONFLICT for bulk upsert (SUPER FAST!)\n        execute_values(\n            cursor,\n            \"\"\"\n            INSERT INTO yfinance.ohlcv_data\n            (security_id, date, open, high, low, close, volume)\n            VALUES %s\n            ON CONFLICT (security_id, date)\n            DO UPDATE SET\n                open = EXCLUDED.open,\n                high = EXCLUDED.high,\n                low = EXCLUDED.low,\n                close = EXCLUDED.close,\n                volume = EXCLUDED.volume\n            \"\"\",\n            insert_data,\n            template=None,  # Use default template\n            page_size=1000  # Process 1000 rows at a time\n        )\n\n        # Get rows affected from cursor\n        rows = cursor.rowcount # row update/insert count\n\n        # Commit the changes\n        raw_conn.commit()\n        cursor.close()\n        return {\n            'success': True,\n            'ticker': ticker,\n            'rows_affected': rows,\n            'message': f\"Insert OHLCV for {ticker}\" if rows &gt; 0 else f\"{ticker} already in OHLCV DB\"\n        }\n\n    except Exception as e:\n        # Rollback both the raw connection and session\n        try:\n            raw_conn.rollback()\n        except:\n            pass\n        session.rollback()\n        logger.error(f\"Failed to insert OHLCV data for {ticker}: {e}\")\n        raise Exception(f\"OHLCV insertion failed for {ticker}: {str(e)}\") from e\n\n    finally:\n        session.close()\n</code></pre>"},{"location":"data_pipeline/components/yfinance_client/#sec_master_db.clients.yfinance_client.YfinanceClient.insert_security","title":"<code>insert_security(ticker, groupings, provider='yfinance')</code>","text":"<p>Insert a ticker symbol into the security_master.securities table.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol (e.g., 'AAPL')</p> required <code>groupings</code> <code>List[str]</code> <p>List of grouping tags (e.g., ['sp500', 'tech', 'large-cap'])</p> required <code>provider</code> <code>str</code> <p>Data provider name (default: 'yfinance')</p> <code>'yfinance'</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>{ 'success': bool, 'ticker': str, 'rows_affected': int, 'message': str</p> <p>}</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If database insertion fails</p> Example <p>result = client.insert_security('AAPL', ['sp500', 'nasdaq']) if result['rows_affected'] &gt; 0:     print(\"Inserted successfully\")</p> Note <p>Uses ON CONFLICT DO NOTHING, so duplicate tickers return rowcount=0.</p> Source code in <code>data_pipeline/sec_master_db/clients/yfinance_client.py</code> <pre><code>def insert_security(self, ticker: str, groupings: List[str], provider: str = 'yfinance'):\n    \"\"\"\n    Insert a ticker symbol into the security_master.securities table.\n\n    Args:\n        ticker: Ticker symbol (e.g., 'AAPL')\n        groupings: List of grouping tags (e.g., ['sp500', 'tech', 'large-cap'])\n        provider: Data provider name (default: 'yfinance')\n\n    Returns:\n        dict: {\n            'success': bool,\n            'ticker': str,\n            'rows_affected': int,\n            'message': str\n        }\n\n    Raises:\n        Exception: If database insertion fails\n\n    Example:\n        result = client.insert_security('AAPL', ['sp500', 'nasdaq'])\n        if result['rows_affected'] &gt; 0:\n            print(\"Inserted successfully\")\n\n    Note:\n        Uses ON CONFLICT DO NOTHING, so duplicate tickers return rowcount=0.\n    \"\"\"\n\n    session = self.Session()\n\n    try:\n\n        # Insert a security\n        query = text(\"\"\"\n            INSERT INTO security_master.securities (ticker, provider, groupings, created_at)\n            VALUES (:ticker, :provider, :groupings, NOW())\n            ON CONFLICT (ticker, provider)\n            DO NOTHING\n        \"\"\")\n\n        # Execute query\n        result = session.execute(query, {'ticker': ticker, 'provider': provider, 'groupings': groupings})\n\n        # Get the number of affected rows\n        rows = getattr(result, 'rowcount', 0)\n\n        # Commit saves DB changes\n        session.commit()\n\n        # Return a formatted summary dict\n        return {\n            'success': True,\n            'ticker': ticker,\n            'rows_affected': rows,\n            'message': f\"Inserted {ticker}\" if rows &gt; 0 else f\"{ticker} already exists\"\n        }\n\n    # Catch Error\n    except Exception as e:\n        session.rollback()  # Important: rollback on error so we dont commit partial data\n        logger.error(f\"Failed to insert security {ticker}: {e}\")\n        raise Exception(f\"Security insertion failed for {ticker}: {str(e)}\") from e\n    finally:\n        session.close()\n</code></pre>"},{"location":"data_pipeline/components/yfinance_pipeline/","title":"YfinancePipeline API Reference","text":""},{"location":"data_pipeline/components/yfinance_pipeline/#sec_data_pipeline.yfinance.yfinance_pipeline.YfinancePipeline","title":"<code>sec_data_pipeline.yfinance.yfinance_pipeline.YfinancePipeline</code>","text":"<p>Main data pipeline with date range and incremental scraping - Atomic methods (should be bareboned &amp; simple) - No retry logic &amp; debug logging only (maybe error log) NO INFO LOGS! - Each method should download data for one stock (airflow handles parallel execution)</p> Source code in <code>data_pipeline/sec_data_pipeline/yfinance/yfinance_pipeline.py</code> <pre><code>class YfinancePipeline:\n    \"\"\"\n    Main data pipeline with date range and incremental scraping\n    - Atomic methods (should be bareboned &amp; simple)\n    - No retry logic &amp; debug logging only (maybe error log) NO INFO LOGS!\n    - Each method should download data for one stock (airflow handles parallel execution)\n    \"\"\"\n\n    # Validation constants\n    TICKER_VALIDATION_TEST_DAYS = 21  # Calendar days to test ticker validity\n    MIN_TRADING_DAYS_FOR_VALIDATION = 10  # Minimum trading days required for valid ticker\n    MIN_OHLCV_ROWS_FOR_VALIDATION = 10  # Minimum rows required for OHLCV validation\n    MIN_PRICE_VALUE = 0.01  # Minimum valid price (prevents zero/negative prices)\n    MIN_STDDEV_VALUE = 0.01  # Minimum standard deviation (detects constant values)\n    MAX_TICKER_LENGTH = 5  # Maximum ticker symbol length\n\n    def __init__(self) -&gt; None:\n\n        # Add headers to avoid 403 error (Forbidden, for ticker scraping)\n        self.headers = {\n            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n        }\n\n    def scrape_metadata(self, ticker: str) -&gt; Dict[str, Any]:\n        \"\"\"\n        Scrape fundamental metadata for a single ticker\n\n        Args:\n            ticker: A string for the ticker\n\n        Returns:\n            A dictionary with metadata about the ticker\n        \"\"\"\n\n        # Get the metadata from yfinance\n        stock = yf.Ticker(ticker)\n        info = stock.info\n\n        # Calculate derived metrics\n        current_price = info.get('currentPrice') or info.get('regularMarketPrice')\n        target_price = info.get('targetMeanPrice')\n        target_upside = None\n\n        # Calculate target upside\n        if target_price and current_price:\n            target_upside = (target_price - current_price) / current_price\n\n        # Calculate free cash flow and fcf_yield\n        free_cash_flow = info.get('freeCashflow')\n        market_cap = info.get('marketCap')\n        fcf_yield = None\n        if free_cash_flow and market_cap:\n            fcf_yield = free_cash_flow / market_cap\n\n        # Extract only high and medium availability fields (&gt;50%)\n        metadata = {\n            'ticker': ticker,\n            'date_scraped': date.today(),\n\n            # Company Basic Info (80%+ availability)\n            'company_name': info.get('longName'),\n            'exchange': info.get('exchange'),\n            'country': info.get('country'),\n            'sector': info.get('sector'),\n            'industry': info.get('industry'),\n            'market_cap': market_cap,\n            'enterprise_value': info.get('enterpriseValue'),\n            'shares_outstanding': info.get('sharesOutstanding'),\n            'float_shares': info.get('floatShares'),\n\n            # Valuation Metrics (50%+ availability)\n            'price_to_book': info.get('priceToBook'),\n            'forward_pe': info.get('forwardPE'),\n            'ev_to_ebitda': info.get('enterpriseToEbitda'),\n            'ev_to_revenue': info.get('enterpriseToRevenue'),\n            'price_to_sales': info.get('priceToSalesTrailing12Months'),\n\n            # Profitability &amp; Quality (75%+ availability)\n            'gross_margin': info.get('grossMargins'),\n            'operating_margin': info.get('operatingMargins'),\n            'profit_margin': info.get('profitMargins'),\n            'return_on_equity': info.get('returnOnEquity'),\n            'return_on_assets': info.get('returnOnAssets'),\n            'free_cash_flow_yield': fcf_yield,\n\n            # Growth Metrics (60%+ availability)\n            'revenue_growth_yoy': info.get('revenueGrowth'),\n            'revenue_per_share': info.get('revenuePerShare'),\n\n            # Financial Health (67%+ availability)\n            'debt_to_equity': info.get('debtToEquity'),\n            'current_ratio': info.get('currentRatio'),\n            'quick_ratio': info.get('quickRatio'),\n            'total_cash': info.get('totalCash'),\n            'total_debt': info.get('totalDebt'),\n            'total_cash_per_share': info.get('totalCashPerShare'),\n            'book_value': info.get('bookValue'),\n\n            # Cash Flow (77%+ availability)\n            'operating_cash_flow': info.get('operatingCashflow'),\n            'free_cash_flow': free_cash_flow,\n\n            # Dividends (81%+ availability)\n            'payout_ratio': info.get('payoutRatio'),\n\n            # Short Interest &amp; Ownership (80%+ availability)\n            'short_percent_of_float': info.get('shortPercentOfFloat'),\n            'short_ratio': info.get('shortRatio'),\n            'shares_short': info.get('sharesShort'),\n            'shares_percent_shares_out': info.get('sharesPercentSharesOut'),\n            'held_percent_institutions': info.get('heldPercentInstitutions'),\n            'held_percent_insiders': info.get('heldPercentInsiders'),\n\n            # Analyst Coverage (61%+ availability)\n            'target_mean_price': target_price,\n            'target_price_upside': target_upside,\n            'number_of_analysts': info.get('numberOfAnalystOpinions'),\n            'recommendation_key': info.get('recommendationKey'),\n\n            # Market Performance (80%+ availability)\n            'beta': info.get('beta'),\n            '52_week_high': info.get('fiftyTwoWeekHigh'),\n            '52_week_low': info.get('fiftyTwoWeekLow'),\n            '52_week_change': info.get('52WeekChange'),\n            'sp500_52_week_change': info.get('SandP52WeekChange'),\n            '50_day_average': info.get('fiftyDayAverage'),\n            '200_day_average': info.get('twoHundredDayAverage'),\n\n            # Trading Volume (100% availability)\n            'average_volume': info.get('averageVolume'),\n            'average_volume_10days': info.get('averageDailyVolume10Day'),\n            'regular_market_volume': info.get('regularMarketVolume'),\n\n            # Metadata\n            'last_updated': datetime.now(),\n            'data_source': 'yfinance'\n        }\n\n        # Return metadata\n        return metadata\n\n    def scrape_date_range(\n        self,\n        ticker: str,\n        start_date: date,\n        end_date: date,\n        interval: str = '1d'\n    ) -&gt; pd.DataFrame | None:\n        \"\"\"\n        Scrape historical data for a specific date range for a single ticker\n\n        Args:\n            ticker: A single ticker symbol\n            start_date: Start date\n            end_date: End date\n            interval: Data interval (1d only)\n\n        Returns:\n            Returns a dataframe containing the ohlcv for a single stock\n        \"\"\"\n\n        # Download the data for a ticker\n        ticker_data = yf.download(\n            ticker,\n            start=start_date,\n            end=end_date,\n            interval=interval,\n            progress=False, # Disable individual progress bars\n            auto_adjust=True, # Adjusted close prices (dividends &amp; stock splits)\n        )\n\n        if ticker_data is None:\n            raise ValueError(\"OHLCV data is None\")\n\n        # Flatten MultiIndex columns (yfinance returns MultiIndex for single ticker)\n        if isinstance(ticker_data.columns, pd.MultiIndex):\n            ticker_data.columns = ticker_data.columns.get_level_values(0)\n\n        return ticker_data\n\n    def scrape_sp500_tickers(self) -&gt; List[str]:\n        \"\"\"\n        Scrapes S&amp;P 500 tickers from Wikipedia\n\n        Args:\n            None\n\n        Returns:\n            A list of tickers from the S&amp;P 500\n        \"\"\"\n\n        sp500_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n\n        # Fetch the HTML with headers\n        response = requests.get(sp500_url, headers=self.headers)\n\n        # Read the table from the HTML\n        tables = pd.read_html(response.text)\n        df = tables[0]\n\n        # Extract tickers from Symbol column\n        tickers = df['Symbol'].tolist()\n\n        # Clean tickers (replace dots with dashes for BRK.B -&gt; BRK-B)\n        tickers = [ticker.replace('.', '-') for ticker in tickers]\n\n        return tickers\n\n    def scrape_russell3000_tickers(self) -&gt; List[str]:\n        \"\"\"\n        Scrapes Russell 3000 tickers from iShares IWV ETF holdings\n\n        Args:\n            None\n\n        Returns:\n            A list of tickers from the russell 3000 index   \n        \"\"\"\n\n        # IWV is the iShares Russell 3000 ETF - direct CSV download URL\n        csv_url = \"https://www.ishares.com/us/products/239714/ishares-russell-3000-etf/1467271812596.ajax?fileType=csv&amp;fileName=IWV_holdings&amp;dataType=fund\"\n\n        # Request the csv\n        response = requests.get(csv_url, headers=self.headers)\n\n        # Parse CSV - iShares CSV has metadata in first ~10 rows\n        lines = response.text.split('\\n')\n\n        # Find where the actual data starts (look for \"Ticker\" header)\n        data_start = 0\n        for i, line in enumerate(lines):\n            if 'Ticker' in line:\n                data_start = i\n                break\n\n        # Raise error if the ticker isnt found (only client side exception)\n        if data_start == 0:\n            raise ValueError(\"Could not find ticker data in iShares CSV\")\n\n        # Parse the CSV starting from the data rows (Raw CSV data)\n        csv_data = '\\n'.join(lines[data_start:])\n\n        # Read the raw response from memory\n        df = pd.read_csv(StringIO(csv_data))\n\n        # Extract tickers from the Ticker column\n        tickers = df['Ticker'].dropna().tolist()\n\n        # Clean tickers - remove cash positions and invalid entries\n        tickers = [str(ticker).strip() for ticker in tickers\n                 if ticker and str(ticker).strip()\n                 and not str(ticker).startswith('CASH')\n                 and not str(ticker).startswith('USD')\n                 and len(str(ticker).strip()) &lt;= self.MAX_TICKER_LENGTH]\n\n        return tickers\n\n    def scrape_nasdaq_tickers(self) -&gt; List[str]:\n        \"\"\"\n        Scrapes tickers from nasdaq\n\n        Args:\n            None\n\n        Returns:\n            A list of tickers from the nasdaq\n        \"\"\"\n\n        nasdaq_url = \"https://www.nasdaqtrader.com/dynamic/SymDir/nasdaqlisted.txt\"\n\n        # Read the nasdaq url file with | as the separator\n        df = pd.read_csv(nasdaq_url, sep='|')\n\n        # Remove nan values from the data\n        df = df.dropna(subset=['Symbol']) \n\n        # Extract the Symbol column to a list &amp; remove test symbol\n        tickers = df[df['Test Issue'] == 'N']['Symbol'].tolist()\n\n        # Return ticker list\n        return tickers\n\n    def validate_ticker(self, ticker: str, test_days: int = 21) -&gt; bool:\n        \"\"\"\n        Validate tickers by attempting to download recent data\n\n        Args:\n            ticker: Ticker symbol to download\n            test_days: Number of calendar days of data to test (default 21 days ~ 15 trading days)\n\n        Returns:\n            True if ticker valid, false otherwise\n        \"\"\"\n\n        # Calculate date range\n        end_date = date.today()\n        start_date = end_date - timedelta(days=test_days)\n\n        # Download single ticker with explicit auto_adjust\n        data = yf.download(\n            tickers=ticker,\n            start=start_date,\n            end=end_date,\n            progress=False,\n            threads=False,\n            auto_adjust=True  # Explicitly set to avoid warning\n        )\n\n        # Check if we got valid data with minimum trading days\n        if data is not None and not data.empty and len(data) &gt;= self.MIN_TRADING_DAYS_FOR_VALIDATION:\n            return True\n        else:\n            return False\n\n    def validate_ohlcv(self, df: pd.DataFrame, ticker: str) -&gt; Dict[str, Any]:\n        \"\"\"\n        Comprehensive OHLCV validation for backtest-quality data.\n\n        Validates:\n        - Schema completeness (all required columns)\n        - No null/NaN values\n        - No negative prices or volume\n        - Price logic (High &gt;= Low, Open/Close within range)\n        - Data variability (no constant values)\n        - No gaps in date sequence\n        - Minimum data quality thresholds\n\n        Args:\n            df: DataFrame with OHLCV data (must have Date index)\n            ticker: Ticker symbol\n\n        Returns:\n            dict: {\n                'valid': bool,\n                'total_checks': int,\n                'passed': int,\n                'failed': int,\n                'failed_checks': [list of failed check names]\n            }\n        \"\"\"\n        # type: ignore - Great Expectations type stubs incomplete\n\n        # Suppress GX progress bars and warnings\n        import warnings\n        import logging\n        import os\n        import sys\n\n        warnings.filterwarnings('ignore')\n\n        # Completely disable all GX logging and progress bars\n        logging.getLogger('great_expectations').disabled = True\n        logging.getLogger('great_expectations.core').disabled = True\n        logging.getLogger('great_expectations.data_context').disabled = True\n\n        # Redirect stderr to suppress tqdm progress bars\n        old_stderr = sys.stderr\n        sys.stderr = open(os.devnull, 'w')\n\n        os.environ['GX_ANALYTICS_ENABLED'] = 'False'\n\n        try:\n            context = gx.get_context()\n            data_source = context.data_sources.add_pandas(name=f\"{ticker}_source\")\n            data_asset = data_source.add_dataframe_asset(name=f\"{ticker}_asset\")\n            batch_def = data_asset.add_batch_definition_whole_dataframe(f\"{ticker}_batch\")\n\n            # Comprehensive expectations for backtest-quality data\n            expectations = [\n                # 1. Schema validation - required columns exist (order doesn't matter)\n                gx.expectations.ExpectTableColumnsToMatchSet(\n                    column_set={\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"}\n                ),\n\n                # 2. Null/NaN validation - zero tolerance\n                gx.expectations.ExpectColumnValuesToNotBeNull(column=\"Open\"),\n                gx.expectations.ExpectColumnValuesToNotBeNull(column=\"High\"),\n                gx.expectations.ExpectColumnValuesToNotBeNull(column=\"Low\"),\n                gx.expectations.ExpectColumnValuesToNotBeNull(column=\"Close\"),\n                gx.expectations.ExpectColumnValuesToNotBeNull(column=\"Volume\"),\n\n                # 3. Positive price validation - no negative or zero prices\n                gx.expectations.ExpectColumnValuesToBeBetween(column=\"Open\", min_value=self.MIN_PRICE_VALUE),\n                gx.expectations.ExpectColumnValuesToBeBetween(column=\"High\", min_value=self.MIN_PRICE_VALUE),\n                gx.expectations.ExpectColumnValuesToBeBetween(column=\"Low\", min_value=self.MIN_PRICE_VALUE),\n                gx.expectations.ExpectColumnValuesToBeBetween(column=\"Close\", min_value=self.MIN_PRICE_VALUE),\n\n                # 4. Volume validation - non-negative only (0 volume is valid)\n                gx.expectations.ExpectColumnValuesToBeBetween(column=\"Volume\", min_value=0),\n\n                # 5. Price logic validation - High &gt;= Low\n                gx.expectations.ExpectColumnPairValuesAToBeGreaterThanB(\n                    column_A=\"High\", column_B=\"Low\", or_equal=True\n                ),\n\n                # 6. Open/Close within High/Low range\n                gx.expectations.ExpectColumnPairValuesAToBeGreaterThanB(\n                    column_A=\"High\", column_B=\"Open\", or_equal=True\n                ),\n                gx.expectations.ExpectColumnPairValuesAToBeGreaterThanB(\n                    column_A=\"Open\", column_B=\"Low\", or_equal=True\n                ),\n                gx.expectations.ExpectColumnPairValuesAToBeGreaterThanB(\n                    column_A=\"High\", column_B=\"Close\", or_equal=True\n                ),\n                gx.expectations.ExpectColumnPairValuesAToBeGreaterThanB(\n                    column_A=\"Close\", column_B=\"Low\", or_equal=True\n                ),\n\n                # 7. Data variability - no constant values (stddev &gt; 0)\n                gx.expectations.ExpectColumnStdevToBeBetween(column=\"Close\", min_value=self.MIN_STDDEV_VALUE),\n                gx.expectations.ExpectColumnStdevToBeBetween(column=\"Volume\", min_value=self.MIN_STDDEV_VALUE),\n\n                # 8. Minimum row count - at least 10 trading days\n                gx.expectations.ExpectTableRowCountToBeBetween(min_value=self.MIN_OHLCV_ROWS_FOR_VALIDATION),\n\n                # 9. Unique dates - no duplicate timestamps\n                gx.expectations.ExpectColumnValuesToBeUnique(column=\"Date\") if \"Date\" in df.columns else None,\n            ]\n\n            # Remove None values (for conditional expectations)\n            expectations = [e for e in expectations if e is not None]\n\n            # Run all validations and collect results\n            batch = batch_def.get_batch(batch_parameters={\"dataframe\": df})\n\n            results = []\n            failed_checks = []\n\n            for expectation in expectations:\n                result = batch.validate(expectation)\n                results.append(result)\n\n                if not result.success:\n                    # Get expectation type for better logging\n                    expectation_type = type(expectation).__name__\n                    failed_checks.append(expectation_type)\n\n            passed = sum(1 for r in results if r.success)\n            failed = len(results) - passed\n\n            # Restore stderr\n            sys.stderr = old_stderr\n\n            return {\n                'valid': failed == 0,\n                'total_checks': len(results),\n                'passed': passed,\n                'failed': failed,\n                'failed_checks': failed_checks\n            }\n\n        except Exception as e:\n            # Restore stderr\n            sys.stderr = old_stderr\n\n            # If validation setup fails, raise exception for Airflow to retry\n            raise Exception(f\"OHLCV validation framework failed for {ticker}: {str(e)}\") from e\n</code></pre>"},{"location":"data_pipeline/components/yfinance_pipeline/#sec_data_pipeline.yfinance.yfinance_pipeline.YfinancePipeline.scrape_date_range","title":"<code>scrape_date_range(ticker, start_date, end_date, interval='1d')</code>","text":"<p>Scrape historical data for a specific date range for a single ticker</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>A single ticker symbol</p> required <code>start_date</code> <code>date</code> <p>Start date</p> required <code>end_date</code> <code>date</code> <p>End date</p> required <code>interval</code> <code>str</code> <p>Data interval (1d only)</p> <code>'1d'</code> <p>Returns:</p> Type Description <code>DataFrame | None</code> <p>Returns a dataframe containing the ohlcv for a single stock</p> Source code in <code>data_pipeline/sec_data_pipeline/yfinance/yfinance_pipeline.py</code> <pre><code>def scrape_date_range(\n    self,\n    ticker: str,\n    start_date: date,\n    end_date: date,\n    interval: str = '1d'\n) -&gt; pd.DataFrame | None:\n    \"\"\"\n    Scrape historical data for a specific date range for a single ticker\n\n    Args:\n        ticker: A single ticker symbol\n        start_date: Start date\n        end_date: End date\n        interval: Data interval (1d only)\n\n    Returns:\n        Returns a dataframe containing the ohlcv for a single stock\n    \"\"\"\n\n    # Download the data for a ticker\n    ticker_data = yf.download(\n        ticker,\n        start=start_date,\n        end=end_date,\n        interval=interval,\n        progress=False, # Disable individual progress bars\n        auto_adjust=True, # Adjusted close prices (dividends &amp; stock splits)\n    )\n\n    if ticker_data is None:\n        raise ValueError(\"OHLCV data is None\")\n\n    # Flatten MultiIndex columns (yfinance returns MultiIndex for single ticker)\n    if isinstance(ticker_data.columns, pd.MultiIndex):\n        ticker_data.columns = ticker_data.columns.get_level_values(0)\n\n    return ticker_data\n</code></pre>"},{"location":"data_pipeline/components/yfinance_pipeline/#sec_data_pipeline.yfinance.yfinance_pipeline.YfinancePipeline.scrape_metadata","title":"<code>scrape_metadata(ticker)</code>","text":"<p>Scrape fundamental metadata for a single ticker</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>A string for the ticker</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary with metadata about the ticker</p> Source code in <code>data_pipeline/sec_data_pipeline/yfinance/yfinance_pipeline.py</code> <pre><code>def scrape_metadata(self, ticker: str) -&gt; Dict[str, Any]:\n    \"\"\"\n    Scrape fundamental metadata for a single ticker\n\n    Args:\n        ticker: A string for the ticker\n\n    Returns:\n        A dictionary with metadata about the ticker\n    \"\"\"\n\n    # Get the metadata from yfinance\n    stock = yf.Ticker(ticker)\n    info = stock.info\n\n    # Calculate derived metrics\n    current_price = info.get('currentPrice') or info.get('regularMarketPrice')\n    target_price = info.get('targetMeanPrice')\n    target_upside = None\n\n    # Calculate target upside\n    if target_price and current_price:\n        target_upside = (target_price - current_price) / current_price\n\n    # Calculate free cash flow and fcf_yield\n    free_cash_flow = info.get('freeCashflow')\n    market_cap = info.get('marketCap')\n    fcf_yield = None\n    if free_cash_flow and market_cap:\n        fcf_yield = free_cash_flow / market_cap\n\n    # Extract only high and medium availability fields (&gt;50%)\n    metadata = {\n        'ticker': ticker,\n        'date_scraped': date.today(),\n\n        # Company Basic Info (80%+ availability)\n        'company_name': info.get('longName'),\n        'exchange': info.get('exchange'),\n        'country': info.get('country'),\n        'sector': info.get('sector'),\n        'industry': info.get('industry'),\n        'market_cap': market_cap,\n        'enterprise_value': info.get('enterpriseValue'),\n        'shares_outstanding': info.get('sharesOutstanding'),\n        'float_shares': info.get('floatShares'),\n\n        # Valuation Metrics (50%+ availability)\n        'price_to_book': info.get('priceToBook'),\n        'forward_pe': info.get('forwardPE'),\n        'ev_to_ebitda': info.get('enterpriseToEbitda'),\n        'ev_to_revenue': info.get('enterpriseToRevenue'),\n        'price_to_sales': info.get('priceToSalesTrailing12Months'),\n\n        # Profitability &amp; Quality (75%+ availability)\n        'gross_margin': info.get('grossMargins'),\n        'operating_margin': info.get('operatingMargins'),\n        'profit_margin': info.get('profitMargins'),\n        'return_on_equity': info.get('returnOnEquity'),\n        'return_on_assets': info.get('returnOnAssets'),\n        'free_cash_flow_yield': fcf_yield,\n\n        # Growth Metrics (60%+ availability)\n        'revenue_growth_yoy': info.get('revenueGrowth'),\n        'revenue_per_share': info.get('revenuePerShare'),\n\n        # Financial Health (67%+ availability)\n        'debt_to_equity': info.get('debtToEquity'),\n        'current_ratio': info.get('currentRatio'),\n        'quick_ratio': info.get('quickRatio'),\n        'total_cash': info.get('totalCash'),\n        'total_debt': info.get('totalDebt'),\n        'total_cash_per_share': info.get('totalCashPerShare'),\n        'book_value': info.get('bookValue'),\n\n        # Cash Flow (77%+ availability)\n        'operating_cash_flow': info.get('operatingCashflow'),\n        'free_cash_flow': free_cash_flow,\n\n        # Dividends (81%+ availability)\n        'payout_ratio': info.get('payoutRatio'),\n\n        # Short Interest &amp; Ownership (80%+ availability)\n        'short_percent_of_float': info.get('shortPercentOfFloat'),\n        'short_ratio': info.get('shortRatio'),\n        'shares_short': info.get('sharesShort'),\n        'shares_percent_shares_out': info.get('sharesPercentSharesOut'),\n        'held_percent_institutions': info.get('heldPercentInstitutions'),\n        'held_percent_insiders': info.get('heldPercentInsiders'),\n\n        # Analyst Coverage (61%+ availability)\n        'target_mean_price': target_price,\n        'target_price_upside': target_upside,\n        'number_of_analysts': info.get('numberOfAnalystOpinions'),\n        'recommendation_key': info.get('recommendationKey'),\n\n        # Market Performance (80%+ availability)\n        'beta': info.get('beta'),\n        '52_week_high': info.get('fiftyTwoWeekHigh'),\n        '52_week_low': info.get('fiftyTwoWeekLow'),\n        '52_week_change': info.get('52WeekChange'),\n        'sp500_52_week_change': info.get('SandP52WeekChange'),\n        '50_day_average': info.get('fiftyDayAverage'),\n        '200_day_average': info.get('twoHundredDayAverage'),\n\n        # Trading Volume (100% availability)\n        'average_volume': info.get('averageVolume'),\n        'average_volume_10days': info.get('averageDailyVolume10Day'),\n        'regular_market_volume': info.get('regularMarketVolume'),\n\n        # Metadata\n        'last_updated': datetime.now(),\n        'data_source': 'yfinance'\n    }\n\n    # Return metadata\n    return metadata\n</code></pre>"},{"location":"data_pipeline/components/yfinance_pipeline/#sec_data_pipeline.yfinance.yfinance_pipeline.YfinancePipeline.scrape_nasdaq_tickers","title":"<code>scrape_nasdaq_tickers()</code>","text":"<p>Scrapes tickers from nasdaq</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of tickers from the nasdaq</p> Source code in <code>data_pipeline/sec_data_pipeline/yfinance/yfinance_pipeline.py</code> <pre><code>def scrape_nasdaq_tickers(self) -&gt; List[str]:\n    \"\"\"\n    Scrapes tickers from nasdaq\n\n    Args:\n        None\n\n    Returns:\n        A list of tickers from the nasdaq\n    \"\"\"\n\n    nasdaq_url = \"https://www.nasdaqtrader.com/dynamic/SymDir/nasdaqlisted.txt\"\n\n    # Read the nasdaq url file with | as the separator\n    df = pd.read_csv(nasdaq_url, sep='|')\n\n    # Remove nan values from the data\n    df = df.dropna(subset=['Symbol']) \n\n    # Extract the Symbol column to a list &amp; remove test symbol\n    tickers = df[df['Test Issue'] == 'N']['Symbol'].tolist()\n\n    # Return ticker list\n    return tickers\n</code></pre>"},{"location":"data_pipeline/components/yfinance_pipeline/#sec_data_pipeline.yfinance.yfinance_pipeline.YfinancePipeline.scrape_russell3000_tickers","title":"<code>scrape_russell3000_tickers()</code>","text":"<p>Scrapes Russell 3000 tickers from iShares IWV ETF holdings</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of tickers from the russell 3000 index</p> Source code in <code>data_pipeline/sec_data_pipeline/yfinance/yfinance_pipeline.py</code> <pre><code>def scrape_russell3000_tickers(self) -&gt; List[str]:\n    \"\"\"\n    Scrapes Russell 3000 tickers from iShares IWV ETF holdings\n\n    Args:\n        None\n\n    Returns:\n        A list of tickers from the russell 3000 index   \n    \"\"\"\n\n    # IWV is the iShares Russell 3000 ETF - direct CSV download URL\n    csv_url = \"https://www.ishares.com/us/products/239714/ishares-russell-3000-etf/1467271812596.ajax?fileType=csv&amp;fileName=IWV_holdings&amp;dataType=fund\"\n\n    # Request the csv\n    response = requests.get(csv_url, headers=self.headers)\n\n    # Parse CSV - iShares CSV has metadata in first ~10 rows\n    lines = response.text.split('\\n')\n\n    # Find where the actual data starts (look for \"Ticker\" header)\n    data_start = 0\n    for i, line in enumerate(lines):\n        if 'Ticker' in line:\n            data_start = i\n            break\n\n    # Raise error if the ticker isnt found (only client side exception)\n    if data_start == 0:\n        raise ValueError(\"Could not find ticker data in iShares CSV\")\n\n    # Parse the CSV starting from the data rows (Raw CSV data)\n    csv_data = '\\n'.join(lines[data_start:])\n\n    # Read the raw response from memory\n    df = pd.read_csv(StringIO(csv_data))\n\n    # Extract tickers from the Ticker column\n    tickers = df['Ticker'].dropna().tolist()\n\n    # Clean tickers - remove cash positions and invalid entries\n    tickers = [str(ticker).strip() for ticker in tickers\n             if ticker and str(ticker).strip()\n             and not str(ticker).startswith('CASH')\n             and not str(ticker).startswith('USD')\n             and len(str(ticker).strip()) &lt;= self.MAX_TICKER_LENGTH]\n\n    return tickers\n</code></pre>"},{"location":"data_pipeline/components/yfinance_pipeline/#sec_data_pipeline.yfinance.yfinance_pipeline.YfinancePipeline.scrape_sp500_tickers","title":"<code>scrape_sp500_tickers()</code>","text":"<p>Scrapes S&amp;P 500 tickers from Wikipedia</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of tickers from the S&amp;P 500</p> Source code in <code>data_pipeline/sec_data_pipeline/yfinance/yfinance_pipeline.py</code> <pre><code>def scrape_sp500_tickers(self) -&gt; List[str]:\n    \"\"\"\n    Scrapes S&amp;P 500 tickers from Wikipedia\n\n    Args:\n        None\n\n    Returns:\n        A list of tickers from the S&amp;P 500\n    \"\"\"\n\n    sp500_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n\n    # Fetch the HTML with headers\n    response = requests.get(sp500_url, headers=self.headers)\n\n    # Read the table from the HTML\n    tables = pd.read_html(response.text)\n    df = tables[0]\n\n    # Extract tickers from Symbol column\n    tickers = df['Symbol'].tolist()\n\n    # Clean tickers (replace dots with dashes for BRK.B -&gt; BRK-B)\n    tickers = [ticker.replace('.', '-') for ticker in tickers]\n\n    return tickers\n</code></pre>"},{"location":"data_pipeline/components/yfinance_pipeline/#sec_data_pipeline.yfinance.yfinance_pipeline.YfinancePipeline.validate_ohlcv","title":"<code>validate_ohlcv(df, ticker)</code>","text":"<p>Comprehensive OHLCV validation for backtest-quality data.</p> <p>Validates: - Schema completeness (all required columns) - No null/NaN values - No negative prices or volume - Price logic (High &gt;= Low, Open/Close within range) - Data variability (no constant values) - No gaps in date sequence - Minimum data quality thresholds</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with OHLCV data (must have Date index)</p> required <code>ticker</code> <code>str</code> <p>Ticker symbol</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict[str, Any]</code> <p>{ 'valid': bool, 'total_checks': int, 'passed': int, 'failed': int, 'failed_checks': [list of failed check names]</p> <code>Dict[str, Any]</code> <p>}</p> Source code in <code>data_pipeline/sec_data_pipeline/yfinance/yfinance_pipeline.py</code> <pre><code>def validate_ohlcv(self, df: pd.DataFrame, ticker: str) -&gt; Dict[str, Any]:\n    \"\"\"\n    Comprehensive OHLCV validation for backtest-quality data.\n\n    Validates:\n    - Schema completeness (all required columns)\n    - No null/NaN values\n    - No negative prices or volume\n    - Price logic (High &gt;= Low, Open/Close within range)\n    - Data variability (no constant values)\n    - No gaps in date sequence\n    - Minimum data quality thresholds\n\n    Args:\n        df: DataFrame with OHLCV data (must have Date index)\n        ticker: Ticker symbol\n\n    Returns:\n        dict: {\n            'valid': bool,\n            'total_checks': int,\n            'passed': int,\n            'failed': int,\n            'failed_checks': [list of failed check names]\n        }\n    \"\"\"\n    # type: ignore - Great Expectations type stubs incomplete\n\n    # Suppress GX progress bars and warnings\n    import warnings\n    import logging\n    import os\n    import sys\n\n    warnings.filterwarnings('ignore')\n\n    # Completely disable all GX logging and progress bars\n    logging.getLogger('great_expectations').disabled = True\n    logging.getLogger('great_expectations.core').disabled = True\n    logging.getLogger('great_expectations.data_context').disabled = True\n\n    # Redirect stderr to suppress tqdm progress bars\n    old_stderr = sys.stderr\n    sys.stderr = open(os.devnull, 'w')\n\n    os.environ['GX_ANALYTICS_ENABLED'] = 'False'\n\n    try:\n        context = gx.get_context()\n        data_source = context.data_sources.add_pandas(name=f\"{ticker}_source\")\n        data_asset = data_source.add_dataframe_asset(name=f\"{ticker}_asset\")\n        batch_def = data_asset.add_batch_definition_whole_dataframe(f\"{ticker}_batch\")\n\n        # Comprehensive expectations for backtest-quality data\n        expectations = [\n            # 1. Schema validation - required columns exist (order doesn't matter)\n            gx.expectations.ExpectTableColumnsToMatchSet(\n                column_set={\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"}\n            ),\n\n            # 2. Null/NaN validation - zero tolerance\n            gx.expectations.ExpectColumnValuesToNotBeNull(column=\"Open\"),\n            gx.expectations.ExpectColumnValuesToNotBeNull(column=\"High\"),\n            gx.expectations.ExpectColumnValuesToNotBeNull(column=\"Low\"),\n            gx.expectations.ExpectColumnValuesToNotBeNull(column=\"Close\"),\n            gx.expectations.ExpectColumnValuesToNotBeNull(column=\"Volume\"),\n\n            # 3. Positive price validation - no negative or zero prices\n            gx.expectations.ExpectColumnValuesToBeBetween(column=\"Open\", min_value=self.MIN_PRICE_VALUE),\n            gx.expectations.ExpectColumnValuesToBeBetween(column=\"High\", min_value=self.MIN_PRICE_VALUE),\n            gx.expectations.ExpectColumnValuesToBeBetween(column=\"Low\", min_value=self.MIN_PRICE_VALUE),\n            gx.expectations.ExpectColumnValuesToBeBetween(column=\"Close\", min_value=self.MIN_PRICE_VALUE),\n\n            # 4. Volume validation - non-negative only (0 volume is valid)\n            gx.expectations.ExpectColumnValuesToBeBetween(column=\"Volume\", min_value=0),\n\n            # 5. Price logic validation - High &gt;= Low\n            gx.expectations.ExpectColumnPairValuesAToBeGreaterThanB(\n                column_A=\"High\", column_B=\"Low\", or_equal=True\n            ),\n\n            # 6. Open/Close within High/Low range\n            gx.expectations.ExpectColumnPairValuesAToBeGreaterThanB(\n                column_A=\"High\", column_B=\"Open\", or_equal=True\n            ),\n            gx.expectations.ExpectColumnPairValuesAToBeGreaterThanB(\n                column_A=\"Open\", column_B=\"Low\", or_equal=True\n            ),\n            gx.expectations.ExpectColumnPairValuesAToBeGreaterThanB(\n                column_A=\"High\", column_B=\"Close\", or_equal=True\n            ),\n            gx.expectations.ExpectColumnPairValuesAToBeGreaterThanB(\n                column_A=\"Close\", column_B=\"Low\", or_equal=True\n            ),\n\n            # 7. Data variability - no constant values (stddev &gt; 0)\n            gx.expectations.ExpectColumnStdevToBeBetween(column=\"Close\", min_value=self.MIN_STDDEV_VALUE),\n            gx.expectations.ExpectColumnStdevToBeBetween(column=\"Volume\", min_value=self.MIN_STDDEV_VALUE),\n\n            # 8. Minimum row count - at least 10 trading days\n            gx.expectations.ExpectTableRowCountToBeBetween(min_value=self.MIN_OHLCV_ROWS_FOR_VALIDATION),\n\n            # 9. Unique dates - no duplicate timestamps\n            gx.expectations.ExpectColumnValuesToBeUnique(column=\"Date\") if \"Date\" in df.columns else None,\n        ]\n\n        # Remove None values (for conditional expectations)\n        expectations = [e for e in expectations if e is not None]\n\n        # Run all validations and collect results\n        batch = batch_def.get_batch(batch_parameters={\"dataframe\": df})\n\n        results = []\n        failed_checks = []\n\n        for expectation in expectations:\n            result = batch.validate(expectation)\n            results.append(result)\n\n            if not result.success:\n                # Get expectation type for better logging\n                expectation_type = type(expectation).__name__\n                failed_checks.append(expectation_type)\n\n        passed = sum(1 for r in results if r.success)\n        failed = len(results) - passed\n\n        # Restore stderr\n        sys.stderr = old_stderr\n\n        return {\n            'valid': failed == 0,\n            'total_checks': len(results),\n            'passed': passed,\n            'failed': failed,\n            'failed_checks': failed_checks\n        }\n\n    except Exception as e:\n        # Restore stderr\n        sys.stderr = old_stderr\n\n        # If validation setup fails, raise exception for Airflow to retry\n        raise Exception(f\"OHLCV validation framework failed for {ticker}: {str(e)}\") from e\n</code></pre>"},{"location":"data_pipeline/components/yfinance_pipeline/#sec_data_pipeline.yfinance.yfinance_pipeline.YfinancePipeline.validate_ticker","title":"<code>validate_ticker(ticker, test_days=21)</code>","text":"<p>Validate tickers by attempting to download recent data</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol to download</p> required <code>test_days</code> <code>int</code> <p>Number of calendar days of data to test (default 21 days ~ 15 trading days)</p> <code>21</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if ticker valid, false otherwise</p> Source code in <code>data_pipeline/sec_data_pipeline/yfinance/yfinance_pipeline.py</code> <pre><code>def validate_ticker(self, ticker: str, test_days: int = 21) -&gt; bool:\n    \"\"\"\n    Validate tickers by attempting to download recent data\n\n    Args:\n        ticker: Ticker symbol to download\n        test_days: Number of calendar days of data to test (default 21 days ~ 15 trading days)\n\n    Returns:\n        True if ticker valid, false otherwise\n    \"\"\"\n\n    # Calculate date range\n    end_date = date.today()\n    start_date = end_date - timedelta(days=test_days)\n\n    # Download single ticker with explicit auto_adjust\n    data = yf.download(\n        tickers=ticker,\n        start=start_date,\n        end=end_date,\n        progress=False,\n        threads=False,\n        auto_adjust=True  # Explicitly set to avoid warning\n    )\n\n    # Check if we got valid data with minimum trading days\n    if data is not None and not data.empty and len(data) &gt;= self.MIN_TRADING_DAYS_FOR_VALIDATION:\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"data_pipeline/dags/daily/","title":"Daily Parallel DAG","text":"<p>Incremental daily updates for existing securities.</p>"},{"location":"data_pipeline/dags/daily/#schedule","title":"Schedule","text":"<p>Weekdays at 9:30 PM UTC (after market close)</p>"},{"location":"data_pipeline/dags/daily/#task-flow","title":"Task Flow","text":"<ol> <li>Get tickers from database</li> <li>Download latest OHLCV data</li> <li>Validate OHLCV quality</li> <li>Insert to database</li> <li>Update metadata</li> </ol>"},{"location":"data_pipeline/dags/daily/#configuration","title":"Configuration","text":"<ul> <li>Max parallel tasks: 20</li> <li>Retry: 2-3 attempts </li> <li>Auto-runs weekdays only</li> </ul>"},{"location":"data_pipeline/dags/historical/","title":"Historical Parallel DAG","text":"<p>Bulk historical data loading with parallel per-ticker execution.</p>"},{"location":"data_pipeline/dags/historical/#trigger","title":"Trigger","text":"<p>Manual via Airflow UI</p>"},{"location":"data_pipeline/dags/historical/#parameters","title":"Parameters","text":"<ul> <li>years_back: 1-10 years (default: 10)</li> <li>ticker_source: sp500, russell3000, nasdaq, all</li> <li>ticker_limit: Limit tickers (0 = no limit)</li> </ul>"},{"location":"data_pipeline/dags/historical/#task-flow","title":"Task Flow","text":"<ol> <li>Get tickers from source</li> <li>Validate tickers in parallel</li> <li>Register securities in database</li> <li>Download OHLCV data</li> <li>Validate OHLCV quality</li> <li>Insert to database</li> <li>Download metadata</li> <li>Insert metadata</li> </ol>"},{"location":"data_pipeline/dags/historical/#configuration","title":"Configuration","text":"<ul> <li>Max parallel tasks: 20</li> <li>Retry: 2-3 attempts with exponential backoff</li> <li>Trigger rule: <code>all_done</code> (continues on failures)</li> </ul>"}]}